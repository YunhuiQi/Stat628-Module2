{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This code file is to read jason data and create appropriate format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import math\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "wnl = WordNetLemmatizer() \n",
    "sr = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_word_char(line):\n",
    "    '''\n",
    "    For simplexity we can first ignore special character\n",
    "    \n",
    "    1. Split line if it is not a word character\n",
    "    2. Iterated each word, count if it is one word, count total characters\n",
    "    '''\n",
    "    \n",
    "    words = [word for word in re.split(r'\\W', line) if word.isalnum()] # divide string based on symbol\n",
    "    \n",
    "    symbols = [word.strip() for word in re.split(r'\\w', line) if word not in ['', ' ']] # devide string based on word, only keep symbol not '' or ' '\n",
    "    \n",
    "    wc, cc = 0, 0 # counting \n",
    "    word_dict = {} # word dictionary\n",
    "    \n",
    "    for word in words: # For each word in the word list\n",
    "        \n",
    "        cc += len(word) # add current word characters length\n",
    "        \n",
    "        if not word.isdecimal(): # If the word is a not a pure number\n",
    "            wc += 1 # counter + 1\n",
    "            \n",
    "            # Save word frequency\n",
    "            \n",
    "            if word in word_dict: \n",
    "                word_dict[word] += 1\n",
    "            else:\n",
    "                word_dict[word] = 1  \n",
    "    #print(\"\"\"Symbols are: {}\\nTotal words count: {}\\nTotal character count: {}\\n\"\"\".format(symbols, wc, cc))\n",
    "    \n",
    "    #print(\"-\"*31)\n",
    "    #print(\"{0:15}|{1:>15}\".format(\"Word\", \"Frequency\"))\n",
    "    #print(\"-\"*31)\n",
    "    #for word, frequency in word_dict.items():\n",
    "    #    print(\"{0:15}|{1:>15}\".format(word, frequency))\n",
    "    \n",
    "    return symbols, wc, cc, word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "##define try size \n",
    "trysize=10\n",
    "## read jason data \n",
    "file_name = 'data/review_train.json'\n",
    "review_train = []\n",
    "size=0\n",
    "with open(file_name, 'r') as f:\n",
    "    try:\n",
    "        while size<=(trysize-1):\n",
    "            line = f.readline()\n",
    "            size=size+1\n",
    "            if line:\n",
    "                r = json.loads(line)\n",
    "                review_train.append(r)\n",
    "            else:\n",
    "                break\n",
    "    except:\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'today': 2, 'wa': 16, 'second': 1, 'three': 2, 'session': 3, 'paid': 1, 'although': 1, 'first': 2, 'went': 2, 'well': 5, 'could': 4, 'tell': 1, 'meredith': 1, 'particular': 1, 'enjoyment': 1, 'male': 1, 'client': 1, 'female': 2, 'however': 1, 'returned': 1, 'teeth': 3, 'fine': 1, 'pleased': 1, 'result': 1, 'whitening': 2, 'room': 4, 'gentleman': 1, 'appointment': 1, 'started': 1, 'person': 1, 'service': 1, 'industry': 1, 'always': 1, 'attend': 1, 'clientele': 1, 'couple': 1, 'arrives': 1, 'unbothered': 1, 'sign': 1, 'waited': 2, 'turn': 1, 'checked': 3, 'original': 1, 'minute': 6, 'timer': 1, 'ask': 1, 'ok': 1, 'attended': 1, 'boyfriend': 1, 'numerous': 1, 'occasion': 1, 'men': 1, 'would': 2, 'exit': 1, 'without': 1, 'even': 5, 'asking': 1, 'looking': 1, 'see': 1, 'irritation': 1, 'half': 1, 'way': 3, 'another': 1, 'woman': 2, 'showed': 1, 'explaining': 1, 'deal': 1, 'lobby': 2, 'admits': 1, 'must': 1, 'reset': 6, 'process': 1, 'left': 2, 'rest': 1, 'furthest': 1, 'away': 1, 'time': 7, 'come': 3, 'redeem': 1, 'get': 2, 'set': 1, 'gave': 1, 'done': 1, 'point': 3, 'ago': 1, 'according': 1, 'sat': 1, 'patiently': 1, 'whole': 1, 'major': 1, 'pain': 3, 'gum': 2, 'watched': 1, 'lamp': 1, 'shut': 1, 'two': 4, 'others': 1, 'explained': 1, 'guest': 3, 'never': 3, 'light': 2, 'turned': 1, 'released': 1, 'stance': 1, 'mouth': 1, 'relaxed': 1, 'state': 1, 'assuming': 1, 'getting': 2, 'thirty': 1, 'instead': 1, 'usual': 1, 'yet': 1, 'formula': 1, 'burning': 1, 'neglected': 1, 'began': 2, 'burn': 2, 'lip': 1, 'squealing': 1, 'slapping': 1, 'chair': 2, 'trying': 1, 'attention': 1, 'panic': 1, 'much': 1, 'entered': 1, 'already': 1, 'finally': 1, 'acknowledged': 1, 'asked': 1, 'put': 1, 'vitamin': 1, 'e': 1, 'pictured': 1, 'ha': 1, 'treated': 2, 'neglecting': 1, 'irritated': 1, 'suffer': 1, 'wanted': 2, 'leave': 2, 'kept': 1, 'harassing': 1, 'issue': 1, 'saying': 1, 'totally': 1, 'agree': 1, 'justifiable': 1, 'circumstance': 1, 'irritate': 1, 'easily': 1, 'avoid': 1, 'let': 1, 'know': 1, 'check': 1, 'physical': 1, 'health': 1, 'take': 1, 'admitted': 2, 'accuse': 1, 'coming': 1, 'solid': 1, 'stand': 1, 'every': 1, 'mean': 1, 'bother': 1, 'help': 1, 'proceeded': 1, 'attack': 1, 'simply': 1, 'also': 1, 'expected': 1, 'refund': 1, 'complete': 1, 'due': 1, 'neglect': 1, 'fact': 1, 'returning': 1, 'last': 1, 'failed': 1, 'screaming': 1, 'door': 1, 'continued': 1, 'step': 1, 'life': 1, 'appalled': 1, 'grown': 1, 'behavior': 1, 'claim': 1, 'business': 1, 'year': 1, 'admit': 1, 'wrong': 1, 'make': 1, 'feel': 1, 'unwelcome': 1, 'job': 1, 'properly': 1}\n",
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "## one review example\n",
    "review_example = review_train_try[4]['text']\n",
    "print(review_example)\n",
    "print(type(review_example['wa']))\n",
    "#_, _, _, _ =count_word_char(review_example['text'])\n",
    "#tokens = count_word_char(review_example['text'])[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,trysize):\n",
    "        review = review_train[i]\n",
    "        #print(i)\n",
    "        tokens = count_word_char(review['text'])[3]\n",
    "        clean_tokens = dict()\n",
    "        for token in tokens:\n",
    "            ## change all words into lower form\n",
    "            token_low = token.lower()\n",
    "            ## lemmatization\n",
    "            token_clear = wnl.lemmatize(token_low)\n",
    "            if not token_clear in sr:\n",
    "                clean_tokens[token_clear] = tokens[token]\n",
    "        review_train[i]['text'] = clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'business_id': 31292, 'stars': 1.0, 'text': {'total': 1, 'bill': 1, 'horrible': 1, 'service': 1, '8gs': 1, 'crook': 1, 'actually': 1, 'nerve': 1, 'charge': 1, 'u': 1, 'pill': 2, 'checked': 1, 'online': 1, 'cent': 1, 'avoid': 1, 'hospital': 1, 'er': 1, 'cost': 1}, 'date': '2013-05-07 04:34:36'}, {'business_id': 35344, 'stars': 5.0, 'text': {'adore': 1, 'travis': 6, 'hard': 1, 'rock': 1, 'new': 2, 'kelly': 1, 'cardenas': 1, 'salon': 1, 'always': 1, 'fan': 1, 'great': 1, 'blowout': 5, 'stranger': 1, 'chain': 1, 'offer': 1, 'service': 1, 'however': 1, 'ha': 3, 'taken': 1, 'flawless': 1, 'whole': 1, 'level': 1, 'greets': 1, 'perfectly': 3, 'green': 1, 'swoosh': 1, 'otherwise': 1, 'styled': 1, 'black': 1, 'hair': 4, 'vega': 2, 'worthy': 1, 'rockstar': 1, 'outfit': 1, 'next': 2, 'come': 1, 'relaxing': 1, 'incredible': 1, 'shampoo': 2, 'get': 1, 'full': 1, 'head': 1, 'message': 1, 'could': 1, 'cure': 1, 'even': 1, 'worst': 1, 'migraine': 1, 'minute': 1, 'scented': 1, 'room': 1, 'freakishly': 1, 'strong': 1, 'finger': 1, 'good': 1, 'way': 3, 'use': 1, 'perfect': 1, 'amount': 1, 'pressure': 1, 'wa': 4, 'superb': 1, 'start': 1, 'glorious': 1, 'one': 2, 'two': 1, 'three': 1, 'people': 1, 'involved': 1, 'best': 1, 'round': 1, 'brush': 1, 'action': 1, 'ever': 1, 'seen': 1, 'team': 1, 'stylist': 2, 'clearly': 1, 'along': 1, 'extremely': 1, 'well': 1, 'evident': 1, 'talk': 1, 'help': 1, 'another': 1, 'really': 1, 'genuine': 1, 'corporate': 1, 'requirement': 1, 'much': 1, 'fun': 1, 'started': 1, 'flat': 1, 'iron': 1, 'flipped': 1, 'wrist': 1, 'volume': 1, 'around': 1, 'without': 1, 'making': 1, 'look': 1, 'like': 1, 'texas': 1, 'pagent': 1, 'girl': 1, 'admirable': 1, 'also': 1, 'worth': 1, 'noting': 1, 'fry': 1, 'something': 1, 'happen': 1, 'le': 1, 'skilled': 1, 'end': 1, 'style': 1, 'bouncey': 1, 'looked': 1, 'terrific': 1, 'thing': 1, 'better': 1, 'awesome': 1, 'lasted': 1, 'day': 1, 'see': 1, 'every': 1, 'single': 1, 'time': 1, 'make': 1, 'feel': 1, 'beauuuutiful': 1}, 'date': '2017-01-14 21:30:33'}, {'business_id': 152538, 'stars': 5.0, 'text': {'say': 1, 'office': 4, 'really': 1, 'ha': 2, 'together': 1, 'organized': 1, 'friendly': 2, 'dr': 1, 'j': 1, 'phillipp': 1, 'great': 1, 'dentist': 1, 'professional': 1, 'dental': 3, 'assistant': 1, 'helped': 3, 'procedure': 1, 'amazing': 1, 'jewel': 1, 'bailey': 1, 'feel': 1, 'comfortable': 1, 'insurance': 2, 'purchase': 1, 'something': 1, 'year': 1, 'gave': 1, 'work': 1, 'plus': 1, 'get': 1, 'signed': 1, 'care': 1, 'credit': 1, 'knew': 1, 'nothing': 1, 'visit': 1, 'highly': 1, 'recommend': 1, 'nice': 1, 'synergy': 1, 'whole': 1}, 'date': '2016-11-09 20:09:03'}, {'business_id': 71871, 'stars': 5.0, 'text': {'went': 1, 'lunch': 1, 'steak': 1, 'sandwich': 1, 'wa': 3, 'delicious': 2, 'caesar': 1, 'salad': 2, 'absolutely': 1, 'dressing': 2, 'perfect': 2, 'amount': 1, 'distributed': 1, 'perfectly': 1, 'across': 1, 'leaf': 1, 'know': 1, 'going': 1, 'drink': 1, 'price': 1, 'pretty': 1, 'good': 1, 'server': 1, 'dawn': 1, 'friendly': 1, 'accommodating': 1, 'happy': 1, 'summation': 1, 'great': 1, 'pub': 1, 'experience': 1, 'would': 1, 'go': 1}, 'date': '2018-01-09 20:56:38'}, {'business_id': 64913, 'stars': 1.0, 'text': {'today': 2, 'wa': 16, 'second': 1, 'three': 2, 'session': 3, 'paid': 1, 'although': 1, 'first': 2, 'went': 2, 'well': 5, 'could': 4, 'tell': 1, 'meredith': 1, 'particular': 1, 'enjoyment': 1, 'male': 1, 'client': 1, 'female': 2, 'however': 1, 'returned': 1, 'teeth': 3, 'fine': 1, 'pleased': 1, 'result': 1, 'whitening': 2, 'room': 4, 'gentleman': 1, 'appointment': 1, 'started': 1, 'person': 1, 'service': 1, 'industry': 1, 'always': 1, 'attend': 1, 'clientele': 1, 'couple': 1, 'arrives': 1, 'unbothered': 1, 'sign': 1, 'waited': 2, 'turn': 1, 'checked': 3, 'original': 1, 'minute': 6, 'timer': 1, 'ask': 1, 'ok': 1, 'attended': 1, 'boyfriend': 1, 'numerous': 1, 'occasion': 1, 'men': 1, 'would': 2, 'exit': 1, 'without': 1, 'even': 5, 'asking': 1, 'looking': 1, 'see': 1, 'irritation': 1, 'half': 1, 'way': 3, 'another': 1, 'woman': 2, 'showed': 1, 'explaining': 1, 'deal': 1, 'lobby': 2, 'admits': 1, 'must': 1, 'reset': 6, 'process': 1, 'left': 2, 'rest': 1, 'furthest': 1, 'away': 1, 'time': 7, 'come': 3, 'redeem': 1, 'get': 2, 'set': 1, 'gave': 1, 'done': 1, 'point': 3, 'ago': 1, 'according': 1, 'sat': 1, 'patiently': 1, 'whole': 1, 'major': 1, 'pain': 3, 'gum': 2, 'watched': 1, 'lamp': 1, 'shut': 1, 'two': 4, 'others': 1, 'explained': 1, 'guest': 3, 'never': 3, 'light': 2, 'turned': 1, 'released': 1, 'stance': 1, 'mouth': 1, 'relaxed': 1, 'state': 1, 'assuming': 1, 'getting': 2, 'thirty': 1, 'instead': 1, 'usual': 1, 'yet': 1, 'formula': 1, 'burning': 1, 'neglected': 1, 'began': 2, 'burn': 2, 'lip': 1, 'squealing': 1, 'slapping': 1, 'chair': 2, 'trying': 1, 'attention': 1, 'panic': 1, 'much': 1, 'entered': 1, 'already': 1, 'finally': 1, 'acknowledged': 1, 'asked': 1, 'put': 1, 'vitamin': 1, 'e': 1, 'pictured': 1, 'ha': 1, 'treated': 2, 'neglecting': 1, 'irritated': 1, 'suffer': 1, 'wanted': 2, 'leave': 2, 'kept': 1, 'harassing': 1, 'issue': 1, 'saying': 1, 'totally': 1, 'agree': 1, 'justifiable': 1, 'circumstance': 1, 'irritate': 1, 'easily': 1, 'avoid': 1, 'let': 1, 'know': 1, 'check': 1, 'physical': 1, 'health': 1, 'take': 1, 'admitted': 2, 'accuse': 1, 'coming': 1, 'solid': 1, 'stand': 1, 'every': 1, 'mean': 1, 'bother': 1, 'help': 1, 'proceeded': 1, 'attack': 1, 'simply': 1, 'also': 1, 'expected': 1, 'refund': 1, 'complete': 1, 'due': 1, 'neglect': 1, 'fact': 1, 'returning': 1, 'last': 1, 'failed': 1, 'screaming': 1, 'door': 1, 'continued': 1, 'step': 1, 'life': 1, 'appalled': 1, 'grown': 1, 'behavior': 1, 'claim': 1, 'business': 1, 'year': 1, 'admit': 1, 'wrong': 1, 'make': 1, 'feel': 1, 'unwelcome': 1, 'job': 1, 'properly': 1}, 'date': '2018-01-30 23:07:38'}, {'business_id': 112310, 'stars': 4.0, 'text': {'first': 1, 'admit': 1, 'wa': 9, 'excited': 1, 'going': 1, 'la': 1, 'tavolta': 1, 'food': 2, 'snob': 1, 'group': 3, 'friend': 1, 'suggested': 1, 'go': 1, 'dinner': 1, 'looked': 1, 'online': 1, 'menu': 1, 'nothing': 1, 'special': 3, 'seemed': 2, 'overpriced': 1, 'im': 1, 'also': 3, 'big': 2, 'ordering': 1, 'pasta': 1, 'ala': 1, 'outnumbered': 1, 'thank': 1, 'goodness': 1, 'ordered': 1, 'sea': 2, 'bass': 2, 'die': 1, 'cooked': 1, 'perfectly': 2, 'seasoned': 1, 'perfect': 1, 'portion': 1, 'say': 2, 'enough': 1, 'good': 4, 'thing': 1, 'dish': 2, 'server': 1, 'asked': 1, 'proud': 1, 'said': 1, 'chef': 1, 'incredible': 1, 'job': 1, 'doe': 1, 'hubby': 1, 'got': 1, 'crab': 2, 'tortellini': 2, 'loved': 1, 'heard': 1, 'mmmm': 1, 'around': 1, 'table': 1, 'waiter': 1, 'super': 1, 'nice': 1, 'even': 1, 'gave': 1, 'u': 1, 'free': 1, 'dessert': 1, 'last': 1, 'people': 2, 'restaurant': 1, 'service': 1, 'slow': 1, 'place': 1, 'packed': 1, 'jug': 1, 'wine': 1, 'large': 2, 'conversation': 1, 'seem': 1, 'bother': 1, 'anyone': 1, 'order': 1, 'calamari': 1, 'fried': 1, 'zucchini': 1, 'appetizer': 1, 'leave': 1, 'mussel': 1, 'highly': 1, 'recommend': 1, 'chicken': 2, 'parm': 1, 'romano': 1, 'bit': 1, 'bland': 1, 'house': 1, 'salad': 1, 'teeny': 1, 'make': 1, 'reservation': 1, 'still': 1, 'expect': 1, 'wait': 1, 'plan': 1, 'loud': 1, 'date': 1, 'unless': 1, 'fighting': 1, 'feel': 1, 'like': 1, 'hearing': 1, 'anything': 1, 'ask': 1, 'sit': 1, 'side': 1, 'room': 1, 'available': 1}, 'date': '2013-01-20 13:25:59'}, {'business_id': 176386, 'stars': 3.0, 'text': {'tracy': 3, 'dessert': 2, 'big': 1, 'name': 1, 'hong': 1, 'kong': 1, 'one': 2, 'first': 1, 'markham': 1, 'place': 1, 'ha': 3, 'many': 2, 'year': 3, 'came': 1, 'chinese': 1, 'must': 2, 'say': 2, 'selection': 1, 'increased': 2, 'tremendously': 2, 'might': 1, 'well': 2, 'add': 1, 'price': 1, 'also': 3, 'waitress': 1, 'gave': 1, 'u': 1, 'tea': 1, 'could': 1, 'taste': 1, 'red': 1, 'date': 1, 'fancy': 1, 'simple': 1, 'taro': 1, 'coconut': 1, 'tapioca': 1, 'pearl': 1, 'wa': 2, 'like': 4, 'something': 1, 'basically': 1, 'crazy': 1, 'literally': 1, 'make': 1, 'home': 1, 'bowl': 1, 'would': 1, 'probably': 1, 'cost': 1, 'ago': 1, 'think': 2, 'still': 1, 'get': 1, 'reasonable': 1, 'wow': 1, 'little': 2, 'top': 1, 'though': 1, 'expensive': 1, 'side': 1, 'saw': 1, 'item': 1, 'menu': 1, 'fish': 1, 'ball': 1, 'chicken': 1, 'wing': 1, 'shaved': 1, 'ice': 1, 'friend': 1, 'got': 1, 'mango': 2, 'drink': 1, 'fresh': 1, 'surprised': 1, 'people': 1, 'come': 1, 'work': 1, 'sunday': 1, 'table': 1, 'always': 1, 'filled': 1, 'amount': 1, 'perfect': 1, 'really': 1, 'waited': 1, 'seat': 1, 'long': 1, 'time': 1, 'kept': 1, 'filling': 1, 'finished': 1}, 'date': '2016-05-07 01:21:02'}, {'business_id': 139555, 'stars': 1.0, 'text': {'place': 2, 'ha': 2, 'gone': 2, 'hill': 2, 'clearly': 1, 'cut': 1, 'back': 1, 'staff': 1, 'food': 2, 'quality': 2, 'many': 1, 'review': 1, 'written': 1, 'menu': 1, 'changed': 1, 'going': 1, 'year': 1, 'service': 1, 'slow': 1, 'salad': 1, 'wa': 2, 'bad': 1, 'get': 1, 'worth': 1, 'spending': 1, 'money': 1, 'option': 1}, 'date': '2010-10-05 19:12:35'}, {'business_id': 50173, 'stars': 3.0, 'text': {'giant': 1, 'best': 1, 'buy': 1, 'register': 1, 'get': 1, 'big': 1, 'deal': 1, 'place': 1}, 'date': '2012-02-29 21:52:43'}, {'business_id': 13172, 'stars': 4.0, 'text': {'like': 1, 'walking': 1, 'back': 1, 'time': 1, 'every': 1, 'saturday': 1, 'morning': 1, 'sister': 2, 'wa': 5, 'bowling': 1, 'league': 1, 'done': 1, 'spend': 2, 'quarter': 1, 'playing': 2, 'pin': 1, 'ball': 1, 'machine': 4, 'mother': 1, 'came': 1, 'pick': 1, 'u': 1, 'daring': 1, 'play': 1, 'hard': 1, 'afraid': 1, 'tilt': 1, 'showing': 1, 'freezing': 1, 'game': 1, 'hand': 1, 'bit': 1, 'gentler': 1, 'wanted': 1, 'make': 1, 'sure': 1, 'got': 1, 'worth': 1, 'place': 1, 'ha': 1, 'row': 2, 'really': 1, 'old': 1, 'mid': 1, 'theme': 1, 'even': 1, 'pac': 1, 'man': 1, 'fun': 2, 'afternoon': 1, 'remembering': 1, 'early': 1, 'teen': 1, 'year': 1}, 'date': '2011-11-30 02:11:15'}]\n"
     ]
    }
   ],
   "source": [
    " print(review_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_train_df = pd.DataFrame(review_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   business_id                 date  stars  \\\n",
      "0        31292  2013-05-07 04:34:36    1.0   \n",
      "1        35344  2017-01-14 21:30:33    5.0   \n",
      "2       152538  2016-11-09 20:09:03    5.0   \n",
      "3        71871  2018-01-09 20:56:38    5.0   \n",
      "4        64913  2018-01-30 23:07:38    1.0   \n",
      "\n",
      "                                                text  \n",
      "0  {'total': 1, 'bill': 1, 'horrible': 1, 'servic...  \n",
      "1  {'adore': 1, 'travis': 6, 'hard': 1, 'rock': 1...  \n",
      "2  {'say': 1, 'office': 4, 'really': 1, 'ha': 2, ...  \n",
      "3  {'went': 1, 'lunch': 1, 'steak': 1, 'sandwich'...  \n",
      "4  {'today': 2, 'wa': 16, 'second': 1, 'three': 2...  \n"
     ]
    }
   ],
   "source": [
    "print(review_train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for each review, we compute TF_IDF value for all word, and pick the first five, then combine all first fives and pick first 100 as our predictors for logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "##compute how many reviews in which this key appears\n",
    "def f_appear_num(word):\n",
    "    num=0\n",
    "    for i in range(0,trysize):\n",
    "        d = review_train[i]['text']\n",
    "        if word in d == True:\n",
    "            num = num+1\n",
    "    return num\n",
    "\n",
    "\n",
    "## define function to find top 10 tfidf value words.    \n",
    "def tfidf_top10(text):\n",
    "    ## input is a dictionary\n",
    "    tf = dict()\n",
    "    idf = dict()\n",
    "    tfidfvalue = dict()\n",
    "    for key in text:\n",
    "        num = f_appear_num(key)\n",
    "        tf[key] = text[key]/len(text)\n",
    "        idf[key] = math.log(10/(1+num)) ##change 10 into number of reviews\n",
    "        tfidfvalue[key]= tf[key]*idf[key]\n",
    "    tfidfvalue=sorted(tfidfvalue.items(),key=lambda x:x[1],reverse=True)\n",
    "    return tfidfvalue[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('travis', 0.10546191265621584),\n",
       " ('blowout', 0.08788492721351321),\n",
       " ('hair', 0.07030794177081055),\n",
       " ('wa', 0.07030794177081055),\n",
       " ('ha', 0.05273095632810792),\n",
       " ('perfectly', 0.05273095632810792),\n",
       " ('way', 0.05273095632810792),\n",
       " ('new', 0.03515397088540528),\n",
       " ('vega', 0.03515397088540528)]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_top10(review_train[1]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
