{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This file is used to get wordsbag and sentencebag(input of word2vec) for review_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### usage: please change the trysize into total number of reviews in review_train so that you can get information on all data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import math\n",
    "import sklearn\n",
    "import statsmodels.api as sm\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "wnl = WordNetLemmatizer() \n",
    "sr = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## some definitions\n",
    "def get_word(line):\n",
    "    '''\n",
    "    For simplexity we can first ignore special character\n",
    "    \n",
    "    1. Split line if it is not a word character\n",
    "    2. Iterated each word, count if it is one word, count total characters\n",
    "    '''\n",
    "    \n",
    "    words = [word for word in re.split(r'\\W', line) if word.isalnum()] # divide string based on symbol\n",
    "    \n",
    "    #symbols = [word.strip() for word in re.split(r'\\w', line) if word not in ['', ' ']] # devide string based on word, only keep symbol not '' or ' '\n",
    "    \n",
    "    #wc, cc = 0, 0 # counting \n",
    "    #word_dict = [] # word dictionary\n",
    "    \n",
    "    #for word in words: # For each word in the word list\n",
    "        \n",
    "        #cc += len(word) # add current word characters length\n",
    "        \n",
    "        #if not word.isdecimal(): # If the word is a not a pure number\n",
    "            #wc += 1 # counter + 1\n",
    "            \n",
    "            # Save word frequency\n",
    "            \n",
    "            #if word in word_dict: \n",
    "                #word_dict[word] += 1\n",
    "            #else:\n",
    "                #word_dict[word] = 1  \n",
    "    #print(\"\"\"Symbols are: {}\\nTotal words count: {}\\nTotal character count: {}\\n\"\"\".format(symbols, wc, cc))\n",
    "    \n",
    "    #print(\"-\"*31)\n",
    "    #print(\"{0:15}|{1:>15}\".format(\"Word\", \"Frequency\"))\n",
    "    #print(\"-\"*31)\n",
    "    #for word, frequency in word_dict.items():\n",
    "    #    print(\"{0:15}|{1:>15}\".format(word, frequency))\n",
    "    \n",
    "    return words\n",
    "\n",
    "\n",
    "# for each review, we compute TF_IDF value for all word, and pick the first five,\n",
    "# then combine all first fives and pick first 100 as our predictors for logistic regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "##define try size \n",
    "trysize=10\n",
    "## read jason data \n",
    "file_name = 'data/review_train.json'\n",
    "review_train = []\n",
    "size=0\n",
    "with open(file_name, 'r') as f:\n",
    "    try:\n",
    "        while size<=(trysize-1):\n",
    "            line = f.readline()\n",
    "            size=size+1\n",
    "            if line:\n",
    "                r = json.loads(line)\n",
    "                review_train.append(r)\n",
    "            else:\n",
    "                break\n",
    "    except:\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stranger', 'say', 'attend', 'timer', 'start', 'wrong', 'markham', '0', 'register', 'date', 'leaf', 'know', 'always', 'process', 'total', 'could', 'migraine', 'ordered', 'deal', 'incredible', 'j', 'reset', 'burning', 'waitress', 'tell', 'showed', 'actually', 'professional', 'wrist', 'anything', 'returning', 'involved', 'lamp', 'surprised', 'gentler', 'pick', 'outnumbered', 'waiter', 'u', 'get', 'even', 'returned', 'la', 'attack', 'year', 'yet', 'look', 'enjoyment', 'hubby', 'unwelcome', 'table', 'taste', 'saw', 'finger', 'procedure', 'saying', 'office', 'step', 'filled', 'check', 'money', 'like', 'early', 'attended', 'said', 'zucchini', 'shut', 'talk', 'loved', 'got', 'literally', 'menu', 'happen', '5', 'whitening', 'extremely', 'selection', 'swoosh', 'best', 'head', 'guest', 'pub', 'three', 'lunch', 'girl', 'playing', 'began', 'name', 'irritate', 'buy', 'teeth', 'friend', 'fighting', 'accommodating', 'others', 'door', 'first', 'red', 'ago', 'genuine', 'freakishly', '66', 'man', 'reasonable', 'usual', 'excited', 'physical', 'little', 'something', 'occasion', 'entered', 'admitted', 'action', 'sister', 'sat', 'dessert', 'ok', 'relaxed', 'service', 'signed', 'perfect', 'price', 'slapping', 'trying', 'mango', 'special', 'grown', 'justifiable', 'wait', 'friendly', 'rest', 'bass', 'happy', 'put', 'large', 'cardenas', 'fine', 'gum', 'see', 'dental', 'burn', 'e', 'basically', '3', 'tavolta', 'state', 'styled', 'couple', 'crook', 'er', 'one', 'irritated', 'black', 'im', 'crab', 'available', 'feel', 'daring', 'dressing', 'today', 'play', 'nothing', 'simple', 'relaxing', 'shampoo', 'life', 'kelly', 'pictured', 'let', 'pac', 'pagent', 'item', 'teen', 'end', 'outfit', 'knew', 'lasted', 'back', '50', 'industry', 'clientele', 'helped', 'jug', 'squealing', 'thing', 'afraid', 'dr', 'must', 'result', 'however', 'screaming', 'explaining', 'amazing', 'corporate', 'particular', 'sit', 'continued', 'big', 'recommend', 'finally', 'snob', 'green', 'mid', 'health', 'kept', 'machine', 'together', 'treated', 'quarter', 'claim', 'spending', 'awesome', 'go', '30', 'furthest', 'business', 'portion', 'admits', 'cent', 'fun', '10', 'bit', 'harassing', 'level', 'already', 'pretty', 'seasoned', 'experience', 'neglecting', 'boyfriend', 'walking', 'hospital', 'home', 'bailey', 'well', 'acknowledged', 'mmmm', 'order', 'wa', 'game', 'chinese', 'cure', 'turn', 'circumstance', 'doe', 'done', 'checked', '15', 'changed', 'waited', 'leave', 'bad', 'great', 'staff', 'heard', 'expected', 'probably', 'went', 'expect', 'vitamin', 'another', 'turned', 'reservation', 'would', 'arrives', 'tapioca', 'explained', 'bill', 'sign', 'numerous', 'server', 'refund', 'many', 'chair', 'good', 'blowout', 'spend', 'greets', 'gave', 'offer', 'suggested', 'romano', 'ask', 'thirty', 'chain', 'appetizer', 'cooked', 'tilt', 'wow', 'hand', 'hard', 'worst', 'hill', 'chef', 'option', 'taken', 'meredith', 'message', 'rock', 'anyone', 'brush', 'totally', 'highly', 'goodness', 'although', 'whole', 'skilled', 'next', 'coconut', 'le', 'taro', 'showing', 'also', 'female', 'due', 'admirable', 'die', 'light', 'admit', 'loud', 'ever', 'avoid', 'time', 'fact', 'worth', 'mouth', 'properly', 'sea', 'worthy', 'left', 'assuming', 'old', 'issue', 'day', 'suffer', 'looking', 'bland', 'wine', 'seat', 'flawless', 'perfectly', 'fry', 'review', 'requirement', 'adore', 'male', 'appointment', 'mother', 'pleased', 'written', 'mussel', 'teeny', 'simply', 'sandwich', 'ha', 'without', 'going', 'caesar', 'accuse', 'jewel', 'client', 'add', 'seen', 'vega', 'last', 'calamari', 'synergy', 'help', 'solid', 'nerve', 'come', 'shaved', 'stylist', 'plus', 'enough', 'saturday', '19', 'food', '80', 'proceeded', 'asked', 'half', 'slow', 'style', 'salon', 'wing', 'packed', 'formula', 'visit', 'exit', 'lip', 'absolutely', 'drink', 'better', 'assistant', 'appalled', 'mean', '8gs', 'around', 'failed', 'amount', 'looked', 'easily', 'superb', 'organized', 'charge', 'kong', 'phillipp', 'tremendously', 'work', 'fried', 'clearly', 'strong', 'restaurant', 'ball', 'hong', 'second', 'pasta', 'ice', 'watched', 'ala', 'plan', 'beauuuutiful', 'credit', 'crazy', 'people', 'room', 'league', 'evident', 'flat', 'session', 'stand', 'never', 'glorious', 'full', '69', 'gentleman', 'bowl', 'care', 'expensive', 'salad', 'distributed', 'group', 'scented', 'along', 'fresh', 'started', 'much', 'person', 'behavior', 'unbothered', 'bouncey', 'pin', 'way', 'fancy', 'afternoon', 'asking', 'might', 'dawn', 'seem', 'set', 'redeem', 'bother', 'men', 'point', 'pain', 'side', 'lobby', 'free', 'horrible', 'fan', 'pill', 'job', '25', 'top', 'cost', 'travis', 'agree', 'otherwise', 'steak', 'insurance', 'parm', 'chicken', 'think', 'instead', 'tea', 'take', 'ordering', 'thank', 'freezing', 'irritation', 'new', 'pressure', 'tortellini', 'conversation', 'pearl', 'minute', 'theme', 'round', 'hearing', 'bowling', 'volume', 'make', 'panic', 'noting', '4', 'giant', 'neglected', 'making', 'row', 'flipped', 'gone', 'attention', 'overpriced', 'quality', 'dentist', 'away', 'two', 'house', 'still', 'sunday', 'woman', 'team', 'summation', 'every', 'nice', 'coming', 'came', 'morning', 'really', 'major', 'finished', 'remembering', 'texas', 'across', 'rockstar', 'tracy', 'hair', 'terrific', 'original', 'comfortable', 'dinner', 'released', 'long', 'stance', 'online', 'though', 'increased', 'single', 'neglect', 'delicious', 'getting', 'unless', 'place', 'wanted', 'super', 'fish', 'use', 'paid', 'purchase', '45', 'according', 'patiently', 'dish', 'seemed', 'iron', 'sure', 'cut', 'filling', 'proud', 'complete']\n"
     ]
    }
   ],
   "source": [
    "wordsbag = [] ## include all non repeated words\n",
    "sentencebag = [] ## include all words' sentence [[spliting words in sentence one],[spliting words in sentence two] ...]\n",
    "for i in range(0,trysize):\n",
    "        review = review_train[i]\n",
    "        tokens = get_word(review['text'])\n",
    "        clean_tokens = []\n",
    "        for token in tokens:\n",
    "            ## change all words into lower form\n",
    "            token_low = token.lower()\n",
    "            ## lemmatization\n",
    "            token_clear = wnl.lemmatize(token_low)\n",
    "            if not token_clear in sr:\n",
    "                clean_tokens.append(token_clear)\n",
    "                wordsbag.append(token_clear)\n",
    "        review_train[i]['text'] = clean_tokens\n",
    "        sentencebag.append(review_train[i]['text'])\n",
    "\n",
    "wordsbag = list(set(wordsbag)) ##Deduplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
