{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import modules\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import math\n",
    "from math import sqrt\n",
    "import sklearn\n",
    "import statsmodels.api as sm\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "from sklearn import linear_model\n",
    "import collections\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import word2vec\n",
    "import multiprocessing\n",
    "import time\n",
    "import inflect\n",
    "from textblob import TextBlob\n",
    "import keras.preprocessing.text as T\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer #该类会将文本中的词语转换为词频矩阵，矩阵元素a[i][j] 表示j词在i类文本下的词频\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "## define stopwords\n",
    "sr = stopwords.words('english')\n",
    "p = inflect.engine()\n",
    "wnl = WordNetLemmatizer() \n",
    "table = str.maketrans('', '', string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read review data\n",
    "data_train=pd.read_csv(\"review_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35033/35033 [01:09<00:00, 504.94it/s]\n"
     ]
    }
   ],
   "source": [
    "## review processiong\n",
    "review_train_clean = [[1]]*len(data_train)\n",
    "##a list  with dict element,you can get a summary of frequency of one review by [i] and frequency for a specific word by [i]['word']\n",
    "frequency_train_clean = [[1]]*len(data_train)  \n",
    "for i in tqdm(range(len(data_train))):\n",
    "    #Change n't into not\n",
    "    x = re.sub(r'n\\'t',' not',data_train.iloc[i]['text'])\n",
    "    #Change not adj into not_adj\n",
    "    x = re.sub(r'not ','not_',x)\n",
    "    #Split into words\n",
    "    x = word_tokenize(x)\n",
    "    #Remove punctuation\n",
    "    x = [w.translate(table) if not re.match(r'not_.*', w) else w for w in x]\n",
    "    #Change numbers into words\n",
    "    x = [p.number_to_words(w) if w.isdigit() else w  for w in x ]\n",
    "    #Remove not alphabetic\n",
    "    x = [w for w in x if w.isalpha() or re.match(r'not_.*',w)]\n",
    "    #Convert to lower case\n",
    "    x = [w.lower() for w in x]\n",
    "    #Remove stop words\n",
    "    x = [w for w in x if not w in sr]\n",
    "    ## lemmatization\n",
    "    x = [wnl.lemmatize(w) for w in x]\n",
    "    review_train_clean[i] = x\n",
    "    frequency_train_clean[i] = collections.Counter(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Worst', 'Gyms', 'I', 'met', '', 'And', 'I', 'would', 'not_come', 'again', '3', 'not_great', '', 'luv']\n",
      "['Worst', 'Gyms', 'I', 'met', '', 'And', 'I', 'would', 'not_come', 'again', 'three', 'not_great', '', 'luv']\n",
      "['worst', 'gyms', 'i', 'met', 'and', 'i', 'would', 'not_come', 'again', 'three', 'not_great', 'luv']\n",
      "['worst', 'gyms', 'met', 'would', 'not_come', 'three', 'not_great', 'luv']\n",
      "['worst', 'gym', 'met', 'would', 'not_come', 'three', 'not_great', 'luv']\n"
     ]
    }
   ],
   "source": [
    "    ## example    \n",
    "    x = \"Worst Gyms I met. And I wouldn't come again 3. not great. luv\"\n",
    "    p = inflect.engine()\n",
    "    x = re.sub(r'n\\'t',' not',x)\n",
    "    #Change not adj into not_adj\n",
    "    x = re.sub(r'not ','not_',x)\n",
    "    #Split into words\n",
    "    x = word_tokenize(x)\n",
    "    #Remove punctuation\n",
    "    x = [w.translate(table) if not re.match(r'not_.*', w) else w for w in x]\n",
    "    print(x)\n",
    "    #Change numbers into words\n",
    "    x = [p.number_to_words(w) if w.isdigit() else w  for w in x ]\n",
    "    print(x)\n",
    "    #Remove not alphabetic\n",
    "    x = [w for w in x if w.isalpha() or re.match(r'not_.*',w)]\n",
    "    #Convert to lower case\n",
    "    x = [w.lower() for w in x]\n",
    "    print(x)\n",
    "    #Remove stop words\n",
    "    x = [w for w in x if not w in sr]\n",
    "    print(x)\n",
    "    ## lemmatization\n",
    "    x = [wnl.lemmatize(w) for w in x]\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35033/35033 [32:34<00:00, 17.93it/s]\n"
     ]
    }
   ],
   "source": [
    "#Remove words with frequency lower than 10\n",
    "def flat(l):\n",
    "    for k in l:\n",
    "        if not isinstance(k, (list, tuple)):\n",
    "            yield k\n",
    "        else:\n",
    "            yield from flat(k)\n",
    "allwords = flat(review_train_clean)\n",
    "allfreq = dict(collections.Counter(allwords))\n",
    "lowfreqwords=sorted(allfreq.items(), key = lambda item:item[1])\n",
    "rem_list_low= [lowfreqwords[k][0] for k in range(len(lowfreqwords)) if lowfreqwords[k][1]<5]\n",
    "\n",
    "for i in tqdm(range(len(data_train))):\n",
    "    x = review_train_clean[i]\n",
    "    #Remove least frequent words\n",
    "    x = [w for w in x if not w in rem_list_low]\n",
    "    review_train_clean[i] = x\n",
    "    frequency_train_clean[i] = collections.Counter(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('gym', 38663), ('class', 23424), ('one', 17590), ('time', 17253), ('get', 17036), ('great', 16288), ('like', 15112), ('place', 15104), ('workout', 13985), ('would', 12920)]\n",
      "[('gym', 8059), ('would', 4728), ('one', 4200), ('membership', 4117), ('time', 3984), ('month', 3733), ('get', 3486), ('told', 3331), ('place', 2673), ('go', 2656)]\n",
      "[('gym', 3425), ('one', 1991), ('time', 1670), ('class', 1597), ('get', 1595), ('like', 1518), ('would', 1422), ('place', 1278), ('people', 1160), ('room', 1143)]\n",
      "[('gym', 4082), ('class', 2303), ('one', 2097), ('like', 1912), ('get', 1800), ('time', 1797), ('room', 1729), ('machine', 1545), ('go', 1468), ('would', 1426)]\n",
      "[('gym', 7626), ('class', 4988), ('like', 3430), ('one', 3351), ('get', 3237), ('great', 3231), ('time', 3155), ('room', 3071), ('machine', 2752), ('place', 2661)]\n",
      "[('gym', 15471), ('class', 12345), ('great', 10621), ('workout', 8913), ('place', 7101), ('get', 6918), ('love', 6674), ('time', 6647), ('one', 5951), ('fitness', 5664)]\n"
     ]
    }
   ],
   "source": [
    "## frequency analysis\n",
    "\n",
    "def flat(l):\n",
    "    for k in l:\n",
    "        if not isinstance(k, (list, tuple)):\n",
    "            yield k\n",
    "        else:\n",
    "            yield from flat(k)\n",
    "# frequency analysis for all data \n",
    "allwords = flat(review_train_clean)\n",
    "allfreq = dict(collections.Counter(allwords))\n",
    "print(sorted(allfreq.items(), key = lambda item:item[1],reverse=True)[0:10])\n",
    "\n",
    "# frequency analysis for star 1 data \n",
    "index1 = data_train[data_train['stars']==1].index.tolist()\n",
    "review_train_clean1 = []\n",
    "for ix in index1:\n",
    "    review_train_clean1.append(review_train_clean[ix])\n",
    "allwords1 = flat(review_train_clean1)\n",
    "allfreq1 = dict(collections.Counter(allwords1))\n",
    "print(sorted(allfreq1.items(), key = lambda item:item[1],reverse=True)[0:10])\n",
    "\n",
    "# frequency analysis for star 2 data \n",
    "index2 = data_train[data_train['stars']==2].index.tolist()\n",
    "review_train_clean2 = []\n",
    "for ix in index2:\n",
    "    review_train_clean2.append(review_train_clean[ix])\n",
    "allwords2 = flat(review_train_clean2)\n",
    "allfreq2 = dict(collections.Counter(allwords2))\n",
    "print(sorted(allfreq2.items(), key = lambda item:item[1],reverse=True)[0:10])\n",
    "\n",
    "# frequency analysis for star 3 data \n",
    "index3 = data_train[data_train['stars']==3].index.tolist()\n",
    "review_train_clean3 = []\n",
    "for ix in index3:\n",
    "    review_train_clean3.append(review_train_clean[ix])\n",
    "allwords3 = flat(review_train_clean3)\n",
    "allfreq3 = dict(collections.Counter(allwords3))\n",
    "print(sorted(allfreq3.items(), key = lambda item:item[1],reverse=True)[0:10])\n",
    "\n",
    "# frequency analysis for star 4 data \n",
    "index4 = data_train[data_train['stars']==4].index.tolist()\n",
    "review_train_clean4 = []\n",
    "for ix in index4:\n",
    "    review_train_clean4.append(review_train_clean[ix])\n",
    "allwords4 = flat(review_train_clean4)\n",
    "allfreq4 = dict(collections.Counter(allwords4))\n",
    "print(sorted(allfreq4.items(), key = lambda item:item[1],reverse=True)[0:10])\n",
    "\n",
    "# frequency analysis for star 5 data \n",
    "index5 = data_train[data_train['stars']==5].index.tolist()\n",
    "review_train_clean5 = []\n",
    "for ix in index5:\n",
    "    review_train_clean5.append(review_train_clean[ix])\n",
    "allwords5 = flat(review_train_clean5)\n",
    "allfreq5 = dict(collections.Counter(allwords5))\n",
    "print(sorted(allfreq5.items(), key = lambda item:item[1],reverse=True)[0:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TFIDF analysis\n",
    "texts =  data_train['text']\n",
    "CV = CountVectorizer(stop_words=sr)\n",
    "freqmatrix = CV.fit_transform(texts)\n",
    "tfidftrans = TfidfTransformer() #该类会统计每个词语的tf-idf权值\n",
    "tfidf = tfidftrans.fit_transform(freqmatrix)  #.fit_transform()方法得到tf-idf矩阵\n",
    "tfidf_df = pd.DataFrame(tfidf.toarray())#.toarray()方法将tf-idf矩阵抽取出来并生成一个数据框，元素a[i][j]表示j词在i类文本中的tf-idf权重\n",
    "tfidf_df.columns = CV.get_feature_names()#获取词袋模型中的所有词语（格式为list) ,作为数据框的columns\n",
    "sort = np.argsort(tfidf.toarray(), axis=1)[:, -5:]  #对tf-idf矩阵每行的值进行排序，输出对应索引，并取每行前五，得到sort,格式为numpy.ndarray\n",
    "names = CV.get_feature_names() #names是一个list，包含所有的分词\n",
    "\n",
    "keywords = pd.Index(names)[sort].values  #将names包含的所有分词作为index，根据sort里返回的的每一行索引对所有分词进行筛选，每一行筛选都得到一列表示该篇文档关键词前五的数组，总列数为文档总数\n",
    "\n",
    "keywords_df = pd.DataFrame({\n",
    "    'top1':keywords[:, 0],   #提取第一行，得到包含所有文档的第1个关键词的数组\n",
    "    'top2':keywords[:, 1],  #提取第二行，得到包含所有文档的第2个关键词的数组\n",
    "    'top3':keywords[:, 2], \n",
    "    'top4':keywords[:, 3], \n",
    "    'top5':keywords[:, 4]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write csv file\n",
    "data_train[\"words\"] = review_train_clean\n",
    "data_train.to_csv(\"review_train_clean.csv\",index=False,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31292</td>\n",
       "      <td>2013-05-07 04:34:36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Total bill for this horrible service? Over $8G...</td>\n",
       "      <td>['total', 'bill', 'horrible', 'service', 'croo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>104374</td>\n",
       "      <td>2015-05-26 07:01:54</td>\n",
       "      <td>4.0</td>\n",
       "      <td>This review is for just the gym facilities as ...</td>\n",
       "      <td>['review', 'gym', 'facility', 'never', 'tried'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>170000</td>\n",
       "      <td>2015-12-28 05:52:45</td>\n",
       "      <td>2.0</td>\n",
       "      <td>There are better and worse Y's for sure.  This...</td>\n",
       "      <td>['better', 'worse', 'sure', 'place', 'nothing'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51689</td>\n",
       "      <td>2013-12-28 22:45:53</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Terrible Gym, the ceiling in the mens shower r...</td>\n",
       "      <td>['terrible', 'gym', 'ceiling', 'men', 'shower'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69171</td>\n",
       "      <td>2013-04-10 17:15:32</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Fitness together\\n\\nI can say nothing but posi...</td>\n",
       "      <td>['fitness', 'together', 'say', 'nothing', 'pos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>178332</td>\n",
       "      <td>2014-09-25 08:55:35</td>\n",
       "      <td>3.0</td>\n",
       "      <td>This Gold's is a pretty good gym..for the pric...</td>\n",
       "      <td>['gold', 'pretty', 'good', 'price', 'cheapest'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>51630</td>\n",
       "      <td>2010-08-21 06:53:33</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Wow...no reviews on here yet? I am surprised.....</td>\n",
       "      <td>['wow', 'no', 'review', 'yet', 'surprised', 'l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>53385</td>\n",
       "      <td>2015-06-08 18:21:10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I love this place! I started my Bootcamp worko...</td>\n",
       "      <td>['love', 'place', 'started', 'bootcamp', 'work...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>151835</td>\n",
       "      <td>2014-10-11 05:55:38</td>\n",
       "      <td>4.0</td>\n",
       "      <td>So far so good...19.99 gets  you and a guest i...</td>\n",
       "      <td>['far', 'good', 'get', 'guest', 'staff', 'nice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>61726</td>\n",
       "      <td>2018-01-21 14:54:04</td>\n",
       "      <td>3.0</td>\n",
       "      <td>GoodLife member for 3 years now... I personall...</td>\n",
       "      <td>['goodlife', 'member', 'three', 'year', 'perso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>141671</td>\n",
       "      <td>2018-02-11 04:23:52</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I have nothing but good things to say about Ja...</td>\n",
       "      <td>['nothing', 'good', 'thing', 'say', 'jason', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13548</td>\n",
       "      <td>2018-10-04 16:42:44</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This by far is probably one of the other place...</td>\n",
       "      <td>['far', 'probably', 'one', 'place', 'worked', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>170000</td>\n",
       "      <td>2012-01-03 15:28:54</td>\n",
       "      <td>4.0</td>\n",
       "      <td>My weekend workout spot.  This is a full servi...</td>\n",
       "      <td>['weekend', 'workout', 'spot', 'full', 'servic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>104170</td>\n",
       "      <td>2010-11-22 15:04:49</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I'm a GoodLife member, and have been for years...</td>\n",
       "      <td>['goodlife', 'member', 'year', 'year', 'switch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>184358</td>\n",
       "      <td>2011-04-22 00:41:05</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Although I wouldn't consider myself uber fit, ...</td>\n",
       "      <td>['although', 'would', 'not_consider', 'uber', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>170347</td>\n",
       "      <td>2014-02-05 18:44:11</td>\n",
       "      <td>3.0</td>\n",
       "      <td>My usual spot to go lift since I live close it...</td>\n",
       "      <td>['usual', 'spot', 'go', 'lift', 'since', 'live...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>142505</td>\n",
       "      <td>2018-05-28 21:31:31</td>\n",
       "      <td>5.0</td>\n",
       "      <td>We love this gym, my son loves the Ninja Zone,...</td>\n",
       "      <td>['love', 'gym', 'son', 'love', 'ninja', 'zone'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>99656</td>\n",
       "      <td>2018-08-04 20:54:05</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Always friendly.  Always clean.  Neighborly.  ...</td>\n",
       "      <td>['always', 'friendly', 'always', 'clean', 'par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>116154</td>\n",
       "      <td>2015-10-12 13:51:02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Worst fucking place on the planet! Waited 30 m...</td>\n",
       "      <td>['worst', 'fucking', 'place', 'planet', 'waite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>27590</td>\n",
       "      <td>2016-11-10 02:20:42</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I've been meaning to write this review for qui...</td>\n",
       "      <td>['meaning', 'write', 'review', 'quite', 'somet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>31292</td>\n",
       "      <td>2017-02-09 06:45:18</td>\n",
       "      <td>4.0</td>\n",
       "      <td>My family has used this ER four times in the p...</td>\n",
       "      <td>['family', 'used', 'er', 'four', 'time', 'past...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>61388</td>\n",
       "      <td>2017-07-08 18:52:20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>This gym is run down. It really feels like the...</td>\n",
       "      <td>['gym', 'run', 'really', 'feel', 'like', 'owne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>104374</td>\n",
       "      <td>2017-03-03 21:50:10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I am incredibly frustrated. Apparently a compa...</td>\n",
       "      <td>['incredibly', 'frustrated', 'apparently', 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>90384</td>\n",
       "      <td>2018-08-04 21:31:48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I have been trying to cancel my membership for...</td>\n",
       "      <td>['trying', 'cancel', 'membership', 'month', 'c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>178332</td>\n",
       "      <td>2013-08-03 17:32:24</td>\n",
       "      <td>3.0</td>\n",
       "      <td>I like Golds Gym on Stephanie because they hav...</td>\n",
       "      <td>['like', 'gold', 'gym', 'stephanie', 'cool', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>140723</td>\n",
       "      <td>2014-07-28 00:54:23</td>\n",
       "      <td>4.0</td>\n",
       "      <td>I'll start out with the pros: this gym is in a...</td>\n",
       "      <td>['start', 'pro', 'gym', 'location', 'not_drive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>155592</td>\n",
       "      <td>2016-09-06 01:06:58</td>\n",
       "      <td>4.0</td>\n",
       "      <td>I really like it here but they need to have so...</td>\n",
       "      <td>['really', 'like', 'need', 'rule', 'place', 'p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>80254</td>\n",
       "      <td>2015-07-16 16:00:52</td>\n",
       "      <td>3.0</td>\n",
       "      <td>***This is not a typical spin class***\\n\\nThis...</td>\n",
       "      <td>['not_a', 'typical', 'spin', 'class', 'studio'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>22591</td>\n",
       "      <td>2009-05-21 14:43:33</td>\n",
       "      <td>2.0</td>\n",
       "      <td>The people working here are awesome.  They are...</td>\n",
       "      <td>['people', 'working', 'awesome', 'nice', 'help...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>92058</td>\n",
       "      <td>2015-03-18 19:34:21</td>\n",
       "      <td>4.0</td>\n",
       "      <td>I've been a member here for about 2 months. Fo...</td>\n",
       "      <td>['member', 'two', 'month', 'roughly', 'twelve'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35003</th>\n",
       "      <td>76201</td>\n",
       "      <td>2015-09-19 07:27:52</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Things are afoot, someone got the memo and tod...</td>\n",
       "      <td>['thing', 'someone', 'got', 'memo', 'today', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35004</th>\n",
       "      <td>50356</td>\n",
       "      <td>2014-09-13 19:45:12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>\"Stop by the pro results training desk and get...</td>\n",
       "      <td>['stop', 'pro', 'result', 'training', 'desk', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35005</th>\n",
       "      <td>100521</td>\n",
       "      <td>2018-04-19 19:18:21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>My wife considered joining this gym. The ameni...</td>\n",
       "      <td>['wife', 'considered', 'joining', 'gym', 'amen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35006</th>\n",
       "      <td>109205</td>\n",
       "      <td>2014-07-12 07:25:22</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I have often been on vacation and visited a sp...</td>\n",
       "      <td>['often', 'vacation', 'visited', 'spa', 'hair'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35007</th>\n",
       "      <td>110330</td>\n",
       "      <td>2015-12-11 14:31:13</td>\n",
       "      <td>5.0</td>\n",
       "      <td>It's a very nice and affordable gym considerin...</td>\n",
       "      <td>['nice', 'affordable', 'gym', 'considering', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35008</th>\n",
       "      <td>31314</td>\n",
       "      <td>2018-10-16 01:55:31</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Offers a variety of classes including pre-scho...</td>\n",
       "      <td>['offer', 'variety', 'class', 'including', 'pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35009</th>\n",
       "      <td>144958</td>\n",
       "      <td>2018-02-20 22:47:26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>My wife and I cancelled our Smart Gym membersh...</td>\n",
       "      <td>['wife', 'cancelled', 'smart', 'gym', 'members...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35010</th>\n",
       "      <td>110330</td>\n",
       "      <td>2017-07-19 15:26:43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AVOID THIS PLACE LIKE THE PLAGUE!\\n\\nBRNADON s...</td>\n",
       "      <td>['avoid', 'place', 'like', 'plague', 'sold', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35011</th>\n",
       "      <td>110330</td>\n",
       "      <td>2011-05-22 18:51:39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Really like the gym most of the time,  except ...</td>\n",
       "      <td>['really', 'like', 'gym', 'time', 'except', 'k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35012</th>\n",
       "      <td>109205</td>\n",
       "      <td>2010-08-14 03:18:12</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Gorgeous spa, great cafe, and wonderful shower...</td>\n",
       "      <td>['gorgeous', 'spa', 'great', 'cafe', 'wonderfu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35013</th>\n",
       "      <td>61383</td>\n",
       "      <td>2013-12-03 17:36:35</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Everyone needs to check out this place! Ryan i...</td>\n",
       "      <td>['everyone', 'need', 'check', 'place', 'ryan',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35014</th>\n",
       "      <td>170936</td>\n",
       "      <td>2017-12-01 19:44:30</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Ah, I have so many good things to say about th...</td>\n",
       "      <td>['ah', 'many', 'good', 'thing', 'say', 'gym', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35015</th>\n",
       "      <td>47876</td>\n",
       "      <td>2018-05-30 20:21:21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I paid way more to have the super sport club m...</td>\n",
       "      <td>['paid', 'way', 'super', 'sport', 'club', 'mem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35016</th>\n",
       "      <td>142396</td>\n",
       "      <td>2018-11-11 18:05:07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Scam artists.When we went for a tour,I told th...</td>\n",
       "      <td>['scam', 'went', 'tour', 'told', 'gym', 'requi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35017</th>\n",
       "      <td>94519</td>\n",
       "      <td>2018-10-13 04:07:46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Anthony Garcia is the the only employee at thi...</td>\n",
       "      <td>['anthony', 'garcia', 'employee', 'location', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35018</th>\n",
       "      <td>175917</td>\n",
       "      <td>2014-07-27 22:30:30</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Went here as an early birthday present for the...</td>\n",
       "      <td>['went', 'early', 'birthday', 'present', 'bff'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35019</th>\n",
       "      <td>47876</td>\n",
       "      <td>2018-02-09 05:35:19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Poor customer service, they make passes promis...</td>\n",
       "      <td>['poor', 'customer', 'service', 'make', 'pass'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35020</th>\n",
       "      <td>53225</td>\n",
       "      <td>2015-05-25 00:02:33</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Full disclosure about me. I am a climber. I ha...</td>\n",
       "      <td>['full', 'disclosure', 'climber', 'happen', 'l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35021</th>\n",
       "      <td>2600</td>\n",
       "      <td>2018-06-07 02:20:19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>If you're looking for a gym, look anywhere els...</td>\n",
       "      <td>['looking', 'gym', 'look', 'anywhere', 'else',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35022</th>\n",
       "      <td>187716</td>\n",
       "      <td>2014-01-30 01:05:22</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I've been a member for over a year now. Love t...</td>\n",
       "      <td>['member', 'year', 'love', 'place', 'great', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35023</th>\n",
       "      <td>110330</td>\n",
       "      <td>2018-08-04 03:28:54</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Did you know Lifetime rates its members? The t...</td>\n",
       "      <td>['know', 'lifetime', 'rate', 'member', 'traine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35024</th>\n",
       "      <td>76201</td>\n",
       "      <td>2015-08-02 21:44:20</td>\n",
       "      <td>4.0</td>\n",
       "      <td>This place is relatively small compared to the...</td>\n",
       "      <td>['place', 'relatively', 'small', 'compared', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35025</th>\n",
       "      <td>100521</td>\n",
       "      <td>2018-01-11 04:39:27</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Pretty good Gym. Have been working out with Be...</td>\n",
       "      <td>['pretty', 'good', 'gym', 'working', 'ben', 'a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35026</th>\n",
       "      <td>143567</td>\n",
       "      <td>2018-10-24 02:02:25</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Love this gym! I've had such great exchanges w...</td>\n",
       "      <td>['love', 'gym', 'great', 'exchange', 'many', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35027</th>\n",
       "      <td>160029</td>\n",
       "      <td>2018-11-02 01:59:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I was satisfied with the staff and the service...</td>\n",
       "      <td>['satisfied', 'staff', 'service', 'gold', 'gym...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35028</th>\n",
       "      <td>144958</td>\n",
       "      <td>2018-08-03 18:44:33</td>\n",
       "      <td>3.0</td>\n",
       "      <td>This place does the trick but isn't what I wou...</td>\n",
       "      <td>['place', 'trick', 'not_what', 'would', 'call'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35029</th>\n",
       "      <td>15559</td>\n",
       "      <td>2018-11-11 23:01:36</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Lovely little boutique gym. Clean with a good ...</td>\n",
       "      <td>['lovely', 'little', 'boutique', 'gym', 'clean...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35030</th>\n",
       "      <td>158388</td>\n",
       "      <td>2015-12-19 00:05:57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>So this is the former 24 Hour Fitness facility...</td>\n",
       "      <td>['former', 'hour', 'fitness', 'facility', 'rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35031</th>\n",
       "      <td>170910</td>\n",
       "      <td>2016-01-26 01:32:58</td>\n",
       "      <td>1.0</td>\n",
       "      <td>This gym is dirty and cannot be safe. They are...</td>\n",
       "      <td>['gym', 'dirty', 'cannotbe', 'safe', 'always',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35032</th>\n",
       "      <td>18890</td>\n",
       "      <td>2018-02-06 23:20:28</td>\n",
       "      <td>5.0</td>\n",
       "      <td>My husband and I joined this gym specifically ...</td>\n",
       "      <td>['husband', 'joined', 'gym', 'specifically', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35033 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       business_id                 date  stars  \\\n",
       "0            31292  2013-05-07 04:34:36    1.0   \n",
       "1           104374  2015-05-26 07:01:54    4.0   \n",
       "2           170000  2015-12-28 05:52:45    2.0   \n",
       "3            51689  2013-12-28 22:45:53    1.0   \n",
       "4            69171  2013-04-10 17:15:32    5.0   \n",
       "5           178332  2014-09-25 08:55:35    3.0   \n",
       "6            51630  2010-08-21 06:53:33    5.0   \n",
       "7            53385  2015-06-08 18:21:10    5.0   \n",
       "8           151835  2014-10-11 05:55:38    4.0   \n",
       "9            61726  2018-01-21 14:54:04    3.0   \n",
       "10          141671  2018-02-11 04:23:52    5.0   \n",
       "11           13548  2018-10-04 16:42:44    5.0   \n",
       "12          170000  2012-01-03 15:28:54    4.0   \n",
       "13          104170  2010-11-22 15:04:49    5.0   \n",
       "14          184358  2011-04-22 00:41:05    4.0   \n",
       "15          170347  2014-02-05 18:44:11    3.0   \n",
       "16          142505  2018-05-28 21:31:31    5.0   \n",
       "17           99656  2018-08-04 20:54:05    5.0   \n",
       "18          116154  2015-10-12 13:51:02    1.0   \n",
       "19           27590  2016-11-10 02:20:42    5.0   \n",
       "20           31292  2017-02-09 06:45:18    4.0   \n",
       "21           61388  2017-07-08 18:52:20    2.0   \n",
       "22          104374  2017-03-03 21:50:10    1.0   \n",
       "23           90384  2018-08-04 21:31:48    1.0   \n",
       "24          178332  2013-08-03 17:32:24    3.0   \n",
       "25          140723  2014-07-28 00:54:23    4.0   \n",
       "26          155592  2016-09-06 01:06:58    4.0   \n",
       "27           80254  2015-07-16 16:00:52    3.0   \n",
       "28           22591  2009-05-21 14:43:33    2.0   \n",
       "29           92058  2015-03-18 19:34:21    4.0   \n",
       "...            ...                  ...    ...   \n",
       "35003        76201  2015-09-19 07:27:52    4.0   \n",
       "35004        50356  2014-09-13 19:45:12    2.0   \n",
       "35005       100521  2018-04-19 19:18:21    1.0   \n",
       "35006       109205  2014-07-12 07:25:22    5.0   \n",
       "35007       110330  2015-12-11 14:31:13    5.0   \n",
       "35008        31314  2018-10-16 01:55:31    5.0   \n",
       "35009       144958  2018-02-20 22:47:26    1.0   \n",
       "35010       110330  2017-07-19 15:26:43    1.0   \n",
       "35011       110330  2011-05-22 18:51:39    1.0   \n",
       "35012       109205  2010-08-14 03:18:12    5.0   \n",
       "35013        61383  2013-12-03 17:36:35    5.0   \n",
       "35014       170936  2017-12-01 19:44:30    5.0   \n",
       "35015        47876  2018-05-30 20:21:21    1.0   \n",
       "35016       142396  2018-11-11 18:05:07    1.0   \n",
       "35017        94519  2018-10-13 04:07:46    2.0   \n",
       "35018       175917  2014-07-27 22:30:30    5.0   \n",
       "35019        47876  2018-02-09 05:35:19    1.0   \n",
       "35020        53225  2015-05-25 00:02:33    3.0   \n",
       "35021         2600  2018-06-07 02:20:19    1.0   \n",
       "35022       187716  2014-01-30 01:05:22    5.0   \n",
       "35023       110330  2018-08-04 03:28:54    2.0   \n",
       "35024        76201  2015-08-02 21:44:20    4.0   \n",
       "35025       100521  2018-01-11 04:39:27    4.0   \n",
       "35026       143567  2018-10-24 02:02:25    5.0   \n",
       "35027       160029  2018-11-02 01:59:00    1.0   \n",
       "35028       144958  2018-08-03 18:44:33    3.0   \n",
       "35029        15559  2018-11-11 23:01:36    5.0   \n",
       "35030       158388  2015-12-19 00:05:57    1.0   \n",
       "35031       170910  2016-01-26 01:32:58    1.0   \n",
       "35032        18890  2018-02-06 23:20:28    5.0   \n",
       "\n",
       "                                                    text  \\\n",
       "0      Total bill for this horrible service? Over $8G...   \n",
       "1      This review is for just the gym facilities as ...   \n",
       "2      There are better and worse Y's for sure.  This...   \n",
       "3      Terrible Gym, the ceiling in the mens shower r...   \n",
       "4      Fitness together\\n\\nI can say nothing but posi...   \n",
       "5      This Gold's is a pretty good gym..for the pric...   \n",
       "6      Wow...no reviews on here yet? I am surprised.....   \n",
       "7      I love this place! I started my Bootcamp worko...   \n",
       "8      So far so good...19.99 gets  you and a guest i...   \n",
       "9      GoodLife member for 3 years now... I personall...   \n",
       "10     I have nothing but good things to say about Ja...   \n",
       "11     This by far is probably one of the other place...   \n",
       "12     My weekend workout spot.  This is a full servi...   \n",
       "13     I'm a GoodLife member, and have been for years...   \n",
       "14     Although I wouldn't consider myself uber fit, ...   \n",
       "15     My usual spot to go lift since I live close it...   \n",
       "16     We love this gym, my son loves the Ninja Zone,...   \n",
       "17     Always friendly.  Always clean.  Neighborly.  ...   \n",
       "18     Worst fucking place on the planet! Waited 30 m...   \n",
       "19     I've been meaning to write this review for qui...   \n",
       "20     My family has used this ER four times in the p...   \n",
       "21     This gym is run down. It really feels like the...   \n",
       "22     I am incredibly frustrated. Apparently a compa...   \n",
       "23     I have been trying to cancel my membership for...   \n",
       "24     I like Golds Gym on Stephanie because they hav...   \n",
       "25     I'll start out with the pros: this gym is in a...   \n",
       "26     I really like it here but they need to have so...   \n",
       "27     ***This is not a typical spin class***\\n\\nThis...   \n",
       "28     The people working here are awesome.  They are...   \n",
       "29     I've been a member here for about 2 months. Fo...   \n",
       "...                                                  ...   \n",
       "35003  Things are afoot, someone got the memo and tod...   \n",
       "35004  \"Stop by the pro results training desk and get...   \n",
       "35005  My wife considered joining this gym. The ameni...   \n",
       "35006  I have often been on vacation and visited a sp...   \n",
       "35007  It's a very nice and affordable gym considerin...   \n",
       "35008  Offers a variety of classes including pre-scho...   \n",
       "35009  My wife and I cancelled our Smart Gym membersh...   \n",
       "35010  AVOID THIS PLACE LIKE THE PLAGUE!\\n\\nBRNADON s...   \n",
       "35011  Really like the gym most of the time,  except ...   \n",
       "35012  Gorgeous spa, great cafe, and wonderful shower...   \n",
       "35013  Everyone needs to check out this place! Ryan i...   \n",
       "35014  Ah, I have so many good things to say about th...   \n",
       "35015  I paid way more to have the super sport club m...   \n",
       "35016  Scam artists.When we went for a tour,I told th...   \n",
       "35017  Anthony Garcia is the the only employee at thi...   \n",
       "35018  Went here as an early birthday present for the...   \n",
       "35019  Poor customer service, they make passes promis...   \n",
       "35020  Full disclosure about me. I am a climber. I ha...   \n",
       "35021  If you're looking for a gym, look anywhere els...   \n",
       "35022  I've been a member for over a year now. Love t...   \n",
       "35023  Did you know Lifetime rates its members? The t...   \n",
       "35024  This place is relatively small compared to the...   \n",
       "35025  Pretty good Gym. Have been working out with Be...   \n",
       "35026  Love this gym! I've had such great exchanges w...   \n",
       "35027  I was satisfied with the staff and the service...   \n",
       "35028  This place does the trick but isn't what I wou...   \n",
       "35029  Lovely little boutique gym. Clean with a good ...   \n",
       "35030  So this is the former 24 Hour Fitness facility...   \n",
       "35031  This gym is dirty and cannot be safe. They are...   \n",
       "35032  My husband and I joined this gym specifically ...   \n",
       "\n",
       "                                                   words  \n",
       "0      ['total', 'bill', 'horrible', 'service', 'croo...  \n",
       "1      ['review', 'gym', 'facility', 'never', 'tried'...  \n",
       "2      ['better', 'worse', 'sure', 'place', 'nothing'...  \n",
       "3      ['terrible', 'gym', 'ceiling', 'men', 'shower'...  \n",
       "4      ['fitness', 'together', 'say', 'nothing', 'pos...  \n",
       "5      ['gold', 'pretty', 'good', 'price', 'cheapest'...  \n",
       "6      ['wow', 'no', 'review', 'yet', 'surprised', 'l...  \n",
       "7      ['love', 'place', 'started', 'bootcamp', 'work...  \n",
       "8      ['far', 'good', 'get', 'guest', 'staff', 'nice...  \n",
       "9      ['goodlife', 'member', 'three', 'year', 'perso...  \n",
       "10     ['nothing', 'good', 'thing', 'say', 'jason', '...  \n",
       "11     ['far', 'probably', 'one', 'place', 'worked', ...  \n",
       "12     ['weekend', 'workout', 'spot', 'full', 'servic...  \n",
       "13     ['goodlife', 'member', 'year', 'year', 'switch...  \n",
       "14     ['although', 'would', 'not_consider', 'uber', ...  \n",
       "15     ['usual', 'spot', 'go', 'lift', 'since', 'live...  \n",
       "16     ['love', 'gym', 'son', 'love', 'ninja', 'zone'...  \n",
       "17     ['always', 'friendly', 'always', 'clean', 'par...  \n",
       "18     ['worst', 'fucking', 'place', 'planet', 'waite...  \n",
       "19     ['meaning', 'write', 'review', 'quite', 'somet...  \n",
       "20     ['family', 'used', 'er', 'four', 'time', 'past...  \n",
       "21     ['gym', 'run', 'really', 'feel', 'like', 'owne...  \n",
       "22     ['incredibly', 'frustrated', 'apparently', 'co...  \n",
       "23     ['trying', 'cancel', 'membership', 'month', 'c...  \n",
       "24     ['like', 'gold', 'gym', 'stephanie', 'cool', '...  \n",
       "25     ['start', 'pro', 'gym', 'location', 'not_drive...  \n",
       "26     ['really', 'like', 'need', 'rule', 'place', 'p...  \n",
       "27     ['not_a', 'typical', 'spin', 'class', 'studio'...  \n",
       "28     ['people', 'working', 'awesome', 'nice', 'help...  \n",
       "29     ['member', 'two', 'month', 'roughly', 'twelve'...  \n",
       "...                                                  ...  \n",
       "35003  ['thing', 'someone', 'got', 'memo', 'today', '...  \n",
       "35004  ['stop', 'pro', 'result', 'training', 'desk', ...  \n",
       "35005  ['wife', 'considered', 'joining', 'gym', 'amen...  \n",
       "35006  ['often', 'vacation', 'visited', 'spa', 'hair'...  \n",
       "35007  ['nice', 'affordable', 'gym', 'considering', '...  \n",
       "35008  ['offer', 'variety', 'class', 'including', 'pr...  \n",
       "35009  ['wife', 'cancelled', 'smart', 'gym', 'members...  \n",
       "35010  ['avoid', 'place', 'like', 'plague', 'sold', '...  \n",
       "35011  ['really', 'like', 'gym', 'time', 'except', 'k...  \n",
       "35012  ['gorgeous', 'spa', 'great', 'cafe', 'wonderfu...  \n",
       "35013  ['everyone', 'need', 'check', 'place', 'ryan',...  \n",
       "35014  ['ah', 'many', 'good', 'thing', 'say', 'gym', ...  \n",
       "35015  ['paid', 'way', 'super', 'sport', 'club', 'mem...  \n",
       "35016  ['scam', 'went', 'tour', 'told', 'gym', 'requi...  \n",
       "35017  ['anthony', 'garcia', 'employee', 'location', ...  \n",
       "35018  ['went', 'early', 'birthday', 'present', 'bff'...  \n",
       "35019  ['poor', 'customer', 'service', 'make', 'pass'...  \n",
       "35020  ['full', 'disclosure', 'climber', 'happen', 'l...  \n",
       "35021  ['looking', 'gym', 'look', 'anywhere', 'else',...  \n",
       "35022  ['member', 'year', 'love', 'place', 'great', '...  \n",
       "35023  ['know', 'lifetime', 'rate', 'member', 'traine...  \n",
       "35024  ['place', 'relatively', 'small', 'compared', '...  \n",
       "35025  ['pretty', 'good', 'gym', 'working', 'ben', 'a...  \n",
       "35026  ['love', 'gym', 'great', 'exchange', 'many', '...  \n",
       "35027  ['satisfied', 'staff', 'service', 'gold', 'gym...  \n",
       "35028  ['place', 'trick', 'not_what', 'would', 'call'...  \n",
       "35029  ['lovely', 'little', 'boutique', 'gym', 'clean...  \n",
       "35030  ['former', 'hour', 'fitness', 'facility', 'rec...  \n",
       "35031  ['gym', 'dirty', 'cannotbe', 'safe', 'always',...  \n",
       "35032  ['husband', 'joined', 'gym', 'specifically', '...  \n",
       "\n",
       "[35033 rows x 5 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check csv file\n",
    "data_train_clean = pd.read_csv(\"review_train_clean.csv\")\n",
    "data_train_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time: 810.5755780000001 Seconds\n"
     ]
    }
   ],
   "source": [
    "## train words embedding model\n",
    "## define dimension of need\n",
    "size = 300\n",
    "start = time.process_time()\n",
    "w2v = Word2Vec(review_train_clean, size=size, window=10, min_count=1,\n",
    "            workers=multiprocessing.cpu_count(), sg=1, iter=10, negative=20)\n",
    "end = time.process_time()\n",
    "print('Running time: %s Seconds'%(end-start))\n",
    "## save model as w2vmodel\n",
    "w2v.save('w2vmodel')\n",
    "## load model\n",
    "model = Word2Vec.load('w2vmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:01<00:00, 2687.83it/s]\n"
     ]
    }
   ],
   "source": [
    "## for each review, get 1*size matrix use average of words matrix \n",
    "trysize=5000\n",
    "predictors = np.empty((trysize,size), float)\n",
    "for i in tqdm(range(trysize)):\n",
    "    predictors[i,] = pd.DataFrame(model.wv[review_train_clean[i]]).mean()\n",
    "    \n",
    "response = pd.DataFrame(data_train)['stars']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [11:18<00:00,  9.35it/s]\n"
     ]
    }
   ],
   "source": [
    "size = 300\n",
    "trysize=5000\n",
    "predictors_weighted = np.empty((trysize,size), float)\n",
    "for i in tqdm(range(trysize)):\n",
    "    tfidf_dict = tfidf_4_web(review_train_clean[i],data_train)\n",
    "    tfidf_mul = []\n",
    "    for word in review_train_clean[i]:\n",
    "        tfidf_mul.append(tfidf_dict[word])\n",
    "    predictors_weighted[i,] = (pd.DataFrame(model.wv[review_train_clean[i]]).mul(tfidf_mul,axis=0)).mean()\n",
    "    \n",
    "response = pd.DataFrame(data_train)['stars']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE =  1.331465358167459\n"
     ]
    }
   ],
   "source": [
    "## logistic regression\n",
    "model_logit = LogisticRegression(solver = 'lbfgs', multi_class='multinomial',max_iter=500)\n",
    "model_logit.fit(predictors_weighted, response)\n",
    "## rmse for regression\n",
    "y_fitted = model_logit.predict(predictors_weighted)\n",
    "print(\"RMSE = \", sqrt(sum(np.square(response-y_fitted)) / len(y_fitted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
