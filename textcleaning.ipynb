{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import modules\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import math\n",
    "from math import sqrt\n",
    "import sklearn\n",
    "import statsmodels.api as sm\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "from sklearn import linear_model\n",
    "import collections\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import word2vec\n",
    "import multiprocessing\n",
    "import time\n",
    "from textblob import TextBlob\n",
    "import keras.preprocessing.text as T\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "\n",
    "wnl = WordNetLemmatizer() \n",
    "table = str.maketrans('', '', string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - '/Users/wanwansu/nltk_data'\n    - '/anaconda3/nltk_data'\n    - '/anaconda3/share/nltk_data'\n    - '/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  Attempted to load \u001b[93mcorpora/stopwords.zip/stopwords/\u001b[0m\n\n  Searched in:\n    - '/Users/wanwansu/nltk_data'\n    - '/anaconda3/nltk_data'\n    - '/anaconda3/share/nltk_data'\n    - '/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-202d042f6929>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## define stopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"not\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"no\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# __class__ to something new:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     86\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;31m# Load the corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    697\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - '/Users/wanwansu/nltk_data'\n    - '/anaconda3/nltk_data'\n    - '/anaconda3/share/nltk_data'\n    - '/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "## define stopwords\n",
    "sr = stopwords.words('english')\n",
    "sr.remove(\"not\")\n",
    "sr.remove(\"no\")\n",
    "sr.remove(\"nor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read review data\n",
    "data_train=pd.read_csv(\"review_train.csv\")\n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## review processiong\n",
    "review_train_clean = [[1]]*len(data_train)\n",
    "##a list  with dict element,you can get a summary of frequency of one review by [i] and frequency for a specific word by [i]['word']\n",
    "frequency_train_clean = [[1]]*len(data_train)  \n",
    "for i in tqdm(range(len(data_train))):\n",
    "    #Split into words\n",
    "    x = word_tokenize(data_train.iloc[i]['text'])\n",
    "    #Change n't into not\n",
    "    x = ['not' if w=='n\\'t' else w for w in x ]\n",
    "    #Remove punctuation\n",
    "    x = [w.translate(table) for w in x]\n",
    "    #Remove not alphabetic\n",
    "    x = [word for word in x if word.isalpha()]\n",
    "    #Convert to lower case\n",
    "    x = [w.lower() for w in x]\n",
    "    #Remove stop words\n",
    "    x = [w for w in x if not w in sr]\n",
    "    ## lemmatization\n",
    "    x = [wnl.lemmatize(w) for w in x]\n",
    "    review_train_clean[i] = x\n",
    "    frequency_train_clean[i] = collections.Counter(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"Worst Gyms I met. And I wouldn't come again.\"\n",
    "x=re.sub(r'n\\'t', ' not', x, count=0, flags=0)\n",
    "print(x)\n",
    "\n",
    "x = word_tokenize(x)\n",
    "print(x)\n",
    "\n",
    "    #Remove punctuation\n",
    "x = [w.translate(table) for w in x]\n",
    "print(x)\n",
    "\n",
    "    #Remove not alphabetic\n",
    "x = [word for word in x if word.isalpha()]\n",
    "print(x)\n",
    "\n",
    "    #Convert to lower case\n",
    "x = [w.lower() for w in x]\n",
    "print(x)\n",
    "\n",
    "    #Remove stop words\n",
    "x = [w for w in x if not w in sr]\n",
    "print(x)\n",
    "\n",
    "    ## lemmatization\n",
    "x = [wnl.lemmatize(w) for w in x]\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat(l):\n",
    "    for k in l:\n",
    "        if not isinstance(k, (list, tuple)):\n",
    "            yield k\n",
    "        else:\n",
    "            yield from flat(k)\n",
    "allwords = flat(review_train_clean)\n",
    "allfreq = dict(collections.Counter(allwords))\n",
    "#Remove words with frequency lower than 10\n",
    "lowfreqwords=sorted(allfreq.items(), key = lambda item:item[1])\n",
    "rem_list_low= [lowfreqwords[k][0] for k in range(len(lowfreqwords)) if lowfreqwords[k][1]<5]\n",
    "#Remove most frequent words\n",
    "sorted(allfreq.items(), key = lambda item:item[1],reverse=True)[0:10]\n",
    "#We consider not great like no as important words, so we just add three more useless words\n",
    "sorted(allfreq.items(), key = lambda item:item[1],reverse=True)[0:14]\n",
    "#The final remove list for most frequent ones are{gym,class,get,time,one,place,workout,would,go,fitness}\n",
    "rem_list_high = ['gym','class','get','time','one','place','workout','would','go','fitness']\n",
    "for i in tqdm(range(len(data_train))):\n",
    "    x = review_train_clean[i]\n",
    "    #Remove most frequent words\n",
    "    x = [w for w in x if not w in rem_list_high]\n",
    "    #Remove least frequent words\n",
    "    x = [w for w in x if not w in rem_list_low]\n",
    "    review_train_clean[i] = x\n",
    "    frequency_train_clean[i] = collections.Counter(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'review_train_clean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8933cf728612>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview_train_clean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"words\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreview_train_clean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"review_train_aftercleaning.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'review_train_clean' is not defined"
     ]
    }
   ],
   "source": [
    "len(review_train_clean)\n",
    "data_train[\"words\"] = review_train_clean\n",
    "data_train.to_csv(\"review_train_aftercleaning.csv\",index=False,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31292</td>\n",
       "      <td>2013-05-07 04:34:36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Total bill for this horrible service? Over $8G...</td>\n",
       "      <td>['total', 'bill', 'horrible', 'service', 'croo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>104374</td>\n",
       "      <td>2015-05-26 07:01:54</td>\n",
       "      <td>4.0</td>\n",
       "      <td>This review is for just the gym facilities as ...</td>\n",
       "      <td>['review', 'facility', 'never', 'tried', 'tann...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>170000</td>\n",
       "      <td>2015-12-28 05:52:45</td>\n",
       "      <td>2.0</td>\n",
       "      <td>There are better and worse Y's for sure.  This...</td>\n",
       "      <td>['better', 'worse', 'sure', 'nothing', 'compar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51689</td>\n",
       "      <td>2013-12-28 22:45:53</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Terrible Gym, the ceiling in the mens shower r...</td>\n",
       "      <td>['terrible', 'ceiling', 'men', 'shower', 'room...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69171</td>\n",
       "      <td>2013-04-10 17:15:32</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Fitness together\\n\\nI can say nothing but posi...</td>\n",
       "      <td>['together', 'say', 'nothing', 'positive', 'th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>178332</td>\n",
       "      <td>2014-09-25 08:55:35</td>\n",
       "      <td>3.0</td>\n",
       "      <td>This Gold's is a pretty good gym..for the pric...</td>\n",
       "      <td>['gold', 'pretty', 'good', 'price', 'cheapest'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>51630</td>\n",
       "      <td>2010-08-21 06:53:33</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Wow...no reviews on here yet? I am surprised.....</td>\n",
       "      <td>['wow', 'no', 'review', 'yet', 'surprised', 'l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>53385</td>\n",
       "      <td>2015-06-08 18:21:10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I love this place! I started my Bootcamp worko...</td>\n",
       "      <td>['love', 'started', 'bootcamp', 'week', 'ago',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>151835</td>\n",
       "      <td>2014-10-11 05:55:38</td>\n",
       "      <td>4.0</td>\n",
       "      <td>So far so good...19.99 gets  you and a guest i...</td>\n",
       "      <td>['far', 'good', 'guest', 'staff', 'nice', 'fri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>61726</td>\n",
       "      <td>2018-01-21 14:54:04</td>\n",
       "      <td>3.0</td>\n",
       "      <td>GoodLife member for 3 years now... I personall...</td>\n",
       "      <td>['goodlife', 'member', 'year', 'personally', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>141671</td>\n",
       "      <td>2018-02-11 04:23:52</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I have nothing but good things to say about Ja...</td>\n",
       "      <td>['nothing', 'good', 'thing', 'say', 'jason', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13548</td>\n",
       "      <td>2018-10-04 16:42:44</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This by far is probably one of the other place...</td>\n",
       "      <td>['far', 'probably', 'worked', 'sweat', 'drippi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>170000</td>\n",
       "      <td>2012-01-03 15:28:54</td>\n",
       "      <td>4.0</td>\n",
       "      <td>My weekend workout spot.  This is a full servi...</td>\n",
       "      <td>['weekend', 'spot', 'full', 'service', 'comple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>104170</td>\n",
       "      <td>2010-11-22 15:04:49</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I'm a GoodLife member, and have been for years...</td>\n",
       "      <td>['goodlife', 'member', 'year', 'year', 'switch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>184358</td>\n",
       "      <td>2011-04-22 00:41:05</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Although I wouldn't consider myself uber fit, ...</td>\n",
       "      <td>['although', 'not', 'consider', 'uber', 'fit',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>170347</td>\n",
       "      <td>2014-02-05 18:44:11</td>\n",
       "      <td>3.0</td>\n",
       "      <td>My usual spot to go lift since I live close it...</td>\n",
       "      <td>['usual', 'spot', 'lift', 'since', 'live', 'cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>142505</td>\n",
       "      <td>2018-05-28 21:31:31</td>\n",
       "      <td>5.0</td>\n",
       "      <td>We love this gym, my son loves the Ninja Zone,...</td>\n",
       "      <td>['love', 'son', 'love', 'ninja', 'zone', 'staf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>99656</td>\n",
       "      <td>2018-08-04 20:54:05</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Always friendly.  Always clean.  Neighborly.  ...</td>\n",
       "      <td>['always', 'friendly', 'always', 'clean', 'par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>116154</td>\n",
       "      <td>2015-10-12 13:51:02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Worst fucking place on the planet! Waited 30 m...</td>\n",
       "      <td>['worst', 'fucking', 'planet', 'waited', 'minu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>27590</td>\n",
       "      <td>2016-11-10 02:20:42</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I've been meaning to write this review for qui...</td>\n",
       "      <td>['meaning', 'write', 'review', 'quite', 'somet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>31292</td>\n",
       "      <td>2017-02-09 06:45:18</td>\n",
       "      <td>4.0</td>\n",
       "      <td>My family has used this ER four times in the p...</td>\n",
       "      <td>['family', 'used', 'er', 'four', 'past', 'year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>61388</td>\n",
       "      <td>2017-07-08 18:52:20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>This gym is run down. It really feels like the...</td>\n",
       "      <td>['run', 'really', 'feel', 'like', 'owner', 'no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>104374</td>\n",
       "      <td>2017-03-03 21:50:10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I am incredibly frustrated. Apparently a compa...</td>\n",
       "      <td>['incredibly', 'frustrated', 'apparently', 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>90384</td>\n",
       "      <td>2018-08-04 21:31:48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I have been trying to cancel my membership for...</td>\n",
       "      <td>['trying', 'cancel', 'membership', 'month', 'c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>178332</td>\n",
       "      <td>2013-08-03 17:32:24</td>\n",
       "      <td>3.0</td>\n",
       "      <td>I like Golds Gym on Stephanie because they hav...</td>\n",
       "      <td>['like', 'gold', 'stephanie', 'cool', 'cardio'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>140723</td>\n",
       "      <td>2014-07-28 00:54:23</td>\n",
       "      <td>4.0</td>\n",
       "      <td>I'll start out with the pros: this gym is in a...</td>\n",
       "      <td>['start', 'pro', 'location', 'not', 'drive', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>155592</td>\n",
       "      <td>2016-09-06 01:06:58</td>\n",
       "      <td>4.0</td>\n",
       "      <td>I really like it here but they need to have so...</td>\n",
       "      <td>['really', 'like', 'need', 'rule', 'pertaining...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>80254</td>\n",
       "      <td>2015-07-16 16:00:52</td>\n",
       "      <td>3.0</td>\n",
       "      <td>***This is not a typical spin class***\\n\\nThis...</td>\n",
       "      <td>['not', 'typical', 'spin', 'studio', 'difficul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>22591</td>\n",
       "      <td>2009-05-21 14:43:33</td>\n",
       "      <td>2.0</td>\n",
       "      <td>The people working here are awesome.  They are...</td>\n",
       "      <td>['people', 'working', 'awesome', 'nice', 'help...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>92058</td>\n",
       "      <td>2015-03-18 19:34:21</td>\n",
       "      <td>4.0</td>\n",
       "      <td>I've been a member here for about 2 months. Fo...</td>\n",
       "      <td>['member', 'month', 'roughly', 'month', 'value...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35003</th>\n",
       "      <td>76201</td>\n",
       "      <td>2015-09-19 07:27:52</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Things are afoot, someone got the memo and tod...</td>\n",
       "      <td>['thing', 'someone', 'got', 'memo', 'today', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35004</th>\n",
       "      <td>50356</td>\n",
       "      <td>2014-09-13 19:45:12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>\"Stop by the pro results training desk and get...</td>\n",
       "      <td>['stop', 'pro', 'result', 'training', 'desk', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35005</th>\n",
       "      <td>100521</td>\n",
       "      <td>2018-04-19 19:18:21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>My wife considered joining this gym. The ameni...</td>\n",
       "      <td>['wife', 'considered', 'joining', 'amenity', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35006</th>\n",
       "      <td>109205</td>\n",
       "      <td>2014-07-12 07:25:22</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I have often been on vacation and visited a sp...</td>\n",
       "      <td>['often', 'vacation', 'visited', 'spa', 'hair'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35007</th>\n",
       "      <td>110330</td>\n",
       "      <td>2015-12-11 14:31:13</td>\n",
       "      <td>5.0</td>\n",
       "      <td>It's a very nice and affordable gym considerin...</td>\n",
       "      <td>['nice', 'affordable', 'considering', 'size', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35008</th>\n",
       "      <td>31314</td>\n",
       "      <td>2018-10-16 01:55:31</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Offers a variety of classes including pre-scho...</td>\n",
       "      <td>['offer', 'variety', 'including', 'preschool',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35009</th>\n",
       "      <td>144958</td>\n",
       "      <td>2018-02-20 22:47:26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>My wife and I cancelled our Smart Gym membersh...</td>\n",
       "      <td>['wife', 'cancelled', 'smart', 'membership', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35010</th>\n",
       "      <td>110330</td>\n",
       "      <td>2017-07-19 15:26:43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AVOID THIS PLACE LIKE THE PLAGUE!\\n\\nBRNADON s...</td>\n",
       "      <td>['avoid', 'like', 'plague', 'sold', 'membershi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35011</th>\n",
       "      <td>110330</td>\n",
       "      <td>2011-05-22 18:51:39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Really like the gym most of the time,  except ...</td>\n",
       "      <td>['really', 'like', 'except', 'kid', 'club', 'k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35012</th>\n",
       "      <td>109205</td>\n",
       "      <td>2010-08-14 03:18:12</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Gorgeous spa, great cafe, and wonderful shower...</td>\n",
       "      <td>['gorgeous', 'spa', 'great', 'cafe', 'wonderfu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35013</th>\n",
       "      <td>61383</td>\n",
       "      <td>2013-12-03 17:36:35</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Everyone needs to check out this place! Ryan i...</td>\n",
       "      <td>['everyone', 'need', 'check', 'ryan', 'true', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35014</th>\n",
       "      <td>170936</td>\n",
       "      <td>2017-12-01 19:44:30</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Ah, I have so many good things to say about th...</td>\n",
       "      <td>['ah', 'many', 'good', 'thing', 'say', 'seeing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35015</th>\n",
       "      <td>47876</td>\n",
       "      <td>2018-05-30 20:21:21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I paid way more to have the super sport club m...</td>\n",
       "      <td>['paid', 'way', 'super', 'sport', 'club', 'mem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35016</th>\n",
       "      <td>142396</td>\n",
       "      <td>2018-11-11 18:05:07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Scam artists.When we went for a tour,I told th...</td>\n",
       "      <td>['scam', 'went', 'tour', 'told', 'requires', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35017</th>\n",
       "      <td>94519</td>\n",
       "      <td>2018-10-13 04:07:46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Anthony Garcia is the the only employee at thi...</td>\n",
       "      <td>['anthony', 'garcia', 'employee', 'location', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35018</th>\n",
       "      <td>175917</td>\n",
       "      <td>2014-07-27 22:30:30</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Went here as an early birthday present for the...</td>\n",
       "      <td>['went', 'early', 'birthday', 'present', 'bff'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35019</th>\n",
       "      <td>47876</td>\n",
       "      <td>2018-02-09 05:35:19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Poor customer service, they make passes promis...</td>\n",
       "      <td>['poor', 'customer', 'service', 'make', 'pass'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35020</th>\n",
       "      <td>53225</td>\n",
       "      <td>2015-05-25 00:02:33</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Full disclosure about me. I am a climber. I ha...</td>\n",
       "      <td>['full', 'disclosure', 'climber', 'happen', 'l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35021</th>\n",
       "      <td>2600</td>\n",
       "      <td>2018-06-07 02:20:19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>If you're looking for a gym, look anywhere els...</td>\n",
       "      <td>['looking', 'look', 'anywhere', 'else', 'horri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35022</th>\n",
       "      <td>187716</td>\n",
       "      <td>2014-01-30 01:05:22</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I've been a member for over a year now. Love t...</td>\n",
       "      <td>['member', 'year', 'love', 'great', 'coach', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35023</th>\n",
       "      <td>110330</td>\n",
       "      <td>2018-08-04 03:28:54</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Did you know Lifetime rates its members? The t...</td>\n",
       "      <td>['know', 'lifetime', 'rate', 'member', 'traine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35024</th>\n",
       "      <td>76201</td>\n",
       "      <td>2015-08-02 21:44:20</td>\n",
       "      <td>4.0</td>\n",
       "      <td>This place is relatively small compared to the...</td>\n",
       "      <td>['relatively', 'small', 'compared', 'big', 'bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35025</th>\n",
       "      <td>100521</td>\n",
       "      <td>2018-01-11 04:39:27</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Pretty good Gym. Have been working out with Be...</td>\n",
       "      <td>['pretty', 'good', 'working', 'ben', 'always',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35026</th>\n",
       "      <td>143567</td>\n",
       "      <td>2018-10-24 02:02:25</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Love this gym! I've had such great exchanges w...</td>\n",
       "      <td>['love', 'great', 'exchange', 'many', 'employe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35027</th>\n",
       "      <td>160029</td>\n",
       "      <td>2018-11-02 01:59:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I was satisfied with the staff and the service...</td>\n",
       "      <td>['satisfied', 'staff', 'service', 'gold', 'can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35028</th>\n",
       "      <td>144958</td>\n",
       "      <td>2018-08-03 18:44:33</td>\n",
       "      <td>3.0</td>\n",
       "      <td>This place does the trick but isn't what I wou...</td>\n",
       "      <td>['trick', 'not', 'call', 'elite', 'reason', 'e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35029</th>\n",
       "      <td>15559</td>\n",
       "      <td>2018-11-11 23:01:36</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Lovely little boutique gym. Clean with a good ...</td>\n",
       "      <td>['lovely', 'little', 'boutique', 'clean', 'goo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35030</th>\n",
       "      <td>158388</td>\n",
       "      <td>2015-12-19 00:05:57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>So this is the former 24 Hour Fitness facility...</td>\n",
       "      <td>['former', 'hour', 'facility', 'recently', 'ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35031</th>\n",
       "      <td>170910</td>\n",
       "      <td>2016-01-26 01:32:58</td>\n",
       "      <td>1.0</td>\n",
       "      <td>This gym is dirty and cannot be safe. They are...</td>\n",
       "      <td>['dirty', 'not', 'safe', 'always', 'sanitizer'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35032</th>\n",
       "      <td>18890</td>\n",
       "      <td>2018-02-06 23:20:28</td>\n",
       "      <td>5.0</td>\n",
       "      <td>My husband and I joined this gym specifically ...</td>\n",
       "      <td>['husband', 'joined', 'specifically', 'locatio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35033 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       business_id                 date  stars  \\\n",
       "0            31292  2013-05-07 04:34:36    1.0   \n",
       "1           104374  2015-05-26 07:01:54    4.0   \n",
       "2           170000  2015-12-28 05:52:45    2.0   \n",
       "3            51689  2013-12-28 22:45:53    1.0   \n",
       "4            69171  2013-04-10 17:15:32    5.0   \n",
       "5           178332  2014-09-25 08:55:35    3.0   \n",
       "6            51630  2010-08-21 06:53:33    5.0   \n",
       "7            53385  2015-06-08 18:21:10    5.0   \n",
       "8           151835  2014-10-11 05:55:38    4.0   \n",
       "9            61726  2018-01-21 14:54:04    3.0   \n",
       "10          141671  2018-02-11 04:23:52    5.0   \n",
       "11           13548  2018-10-04 16:42:44    5.0   \n",
       "12          170000  2012-01-03 15:28:54    4.0   \n",
       "13          104170  2010-11-22 15:04:49    5.0   \n",
       "14          184358  2011-04-22 00:41:05    4.0   \n",
       "15          170347  2014-02-05 18:44:11    3.0   \n",
       "16          142505  2018-05-28 21:31:31    5.0   \n",
       "17           99656  2018-08-04 20:54:05    5.0   \n",
       "18          116154  2015-10-12 13:51:02    1.0   \n",
       "19           27590  2016-11-10 02:20:42    5.0   \n",
       "20           31292  2017-02-09 06:45:18    4.0   \n",
       "21           61388  2017-07-08 18:52:20    2.0   \n",
       "22          104374  2017-03-03 21:50:10    1.0   \n",
       "23           90384  2018-08-04 21:31:48    1.0   \n",
       "24          178332  2013-08-03 17:32:24    3.0   \n",
       "25          140723  2014-07-28 00:54:23    4.0   \n",
       "26          155592  2016-09-06 01:06:58    4.0   \n",
       "27           80254  2015-07-16 16:00:52    3.0   \n",
       "28           22591  2009-05-21 14:43:33    2.0   \n",
       "29           92058  2015-03-18 19:34:21    4.0   \n",
       "...            ...                  ...    ...   \n",
       "35003        76201  2015-09-19 07:27:52    4.0   \n",
       "35004        50356  2014-09-13 19:45:12    2.0   \n",
       "35005       100521  2018-04-19 19:18:21    1.0   \n",
       "35006       109205  2014-07-12 07:25:22    5.0   \n",
       "35007       110330  2015-12-11 14:31:13    5.0   \n",
       "35008        31314  2018-10-16 01:55:31    5.0   \n",
       "35009       144958  2018-02-20 22:47:26    1.0   \n",
       "35010       110330  2017-07-19 15:26:43    1.0   \n",
       "35011       110330  2011-05-22 18:51:39    1.0   \n",
       "35012       109205  2010-08-14 03:18:12    5.0   \n",
       "35013        61383  2013-12-03 17:36:35    5.0   \n",
       "35014       170936  2017-12-01 19:44:30    5.0   \n",
       "35015        47876  2018-05-30 20:21:21    1.0   \n",
       "35016       142396  2018-11-11 18:05:07    1.0   \n",
       "35017        94519  2018-10-13 04:07:46    2.0   \n",
       "35018       175917  2014-07-27 22:30:30    5.0   \n",
       "35019        47876  2018-02-09 05:35:19    1.0   \n",
       "35020        53225  2015-05-25 00:02:33    3.0   \n",
       "35021         2600  2018-06-07 02:20:19    1.0   \n",
       "35022       187716  2014-01-30 01:05:22    5.0   \n",
       "35023       110330  2018-08-04 03:28:54    2.0   \n",
       "35024        76201  2015-08-02 21:44:20    4.0   \n",
       "35025       100521  2018-01-11 04:39:27    4.0   \n",
       "35026       143567  2018-10-24 02:02:25    5.0   \n",
       "35027       160029  2018-11-02 01:59:00    1.0   \n",
       "35028       144958  2018-08-03 18:44:33    3.0   \n",
       "35029        15559  2018-11-11 23:01:36    5.0   \n",
       "35030       158388  2015-12-19 00:05:57    1.0   \n",
       "35031       170910  2016-01-26 01:32:58    1.0   \n",
       "35032        18890  2018-02-06 23:20:28    5.0   \n",
       "\n",
       "                                                    text  \\\n",
       "0      Total bill for this horrible service? Over $8G...   \n",
       "1      This review is for just the gym facilities as ...   \n",
       "2      There are better and worse Y's for sure.  This...   \n",
       "3      Terrible Gym, the ceiling in the mens shower r...   \n",
       "4      Fitness together\\n\\nI can say nothing but posi...   \n",
       "5      This Gold's is a pretty good gym..for the pric...   \n",
       "6      Wow...no reviews on here yet? I am surprised.....   \n",
       "7      I love this place! I started my Bootcamp worko...   \n",
       "8      So far so good...19.99 gets  you and a guest i...   \n",
       "9      GoodLife member for 3 years now... I personall...   \n",
       "10     I have nothing but good things to say about Ja...   \n",
       "11     This by far is probably one of the other place...   \n",
       "12     My weekend workout spot.  This is a full servi...   \n",
       "13     I'm a GoodLife member, and have been for years...   \n",
       "14     Although I wouldn't consider myself uber fit, ...   \n",
       "15     My usual spot to go lift since I live close it...   \n",
       "16     We love this gym, my son loves the Ninja Zone,...   \n",
       "17     Always friendly.  Always clean.  Neighborly.  ...   \n",
       "18     Worst fucking place on the planet! Waited 30 m...   \n",
       "19     I've been meaning to write this review for qui...   \n",
       "20     My family has used this ER four times in the p...   \n",
       "21     This gym is run down. It really feels like the...   \n",
       "22     I am incredibly frustrated. Apparently a compa...   \n",
       "23     I have been trying to cancel my membership for...   \n",
       "24     I like Golds Gym on Stephanie because they hav...   \n",
       "25     I'll start out with the pros: this gym is in a...   \n",
       "26     I really like it here but they need to have so...   \n",
       "27     ***This is not a typical spin class***\\n\\nThis...   \n",
       "28     The people working here are awesome.  They are...   \n",
       "29     I've been a member here for about 2 months. Fo...   \n",
       "...                                                  ...   \n",
       "35003  Things are afoot, someone got the memo and tod...   \n",
       "35004  \"Stop by the pro results training desk and get...   \n",
       "35005  My wife considered joining this gym. The ameni...   \n",
       "35006  I have often been on vacation and visited a sp...   \n",
       "35007  It's a very nice and affordable gym considerin...   \n",
       "35008  Offers a variety of classes including pre-scho...   \n",
       "35009  My wife and I cancelled our Smart Gym membersh...   \n",
       "35010  AVOID THIS PLACE LIKE THE PLAGUE!\\n\\nBRNADON s...   \n",
       "35011  Really like the gym most of the time,  except ...   \n",
       "35012  Gorgeous spa, great cafe, and wonderful shower...   \n",
       "35013  Everyone needs to check out this place! Ryan i...   \n",
       "35014  Ah, I have so many good things to say about th...   \n",
       "35015  I paid way more to have the super sport club m...   \n",
       "35016  Scam artists.When we went for a tour,I told th...   \n",
       "35017  Anthony Garcia is the the only employee at thi...   \n",
       "35018  Went here as an early birthday present for the...   \n",
       "35019  Poor customer service, they make passes promis...   \n",
       "35020  Full disclosure about me. I am a climber. I ha...   \n",
       "35021  If you're looking for a gym, look anywhere els...   \n",
       "35022  I've been a member for over a year now. Love t...   \n",
       "35023  Did you know Lifetime rates its members? The t...   \n",
       "35024  This place is relatively small compared to the...   \n",
       "35025  Pretty good Gym. Have been working out with Be...   \n",
       "35026  Love this gym! I've had such great exchanges w...   \n",
       "35027  I was satisfied with the staff and the service...   \n",
       "35028  This place does the trick but isn't what I wou...   \n",
       "35029  Lovely little boutique gym. Clean with a good ...   \n",
       "35030  So this is the former 24 Hour Fitness facility...   \n",
       "35031  This gym is dirty and cannot be safe. They are...   \n",
       "35032  My husband and I joined this gym specifically ...   \n",
       "\n",
       "                                                   words  \n",
       "0      ['total', 'bill', 'horrible', 'service', 'croo...  \n",
       "1      ['review', 'facility', 'never', 'tried', 'tann...  \n",
       "2      ['better', 'worse', 'sure', 'nothing', 'compar...  \n",
       "3      ['terrible', 'ceiling', 'men', 'shower', 'room...  \n",
       "4      ['together', 'say', 'nothing', 'positive', 'th...  \n",
       "5      ['gold', 'pretty', 'good', 'price', 'cheapest'...  \n",
       "6      ['wow', 'no', 'review', 'yet', 'surprised', 'l...  \n",
       "7      ['love', 'started', 'bootcamp', 'week', 'ago',...  \n",
       "8      ['far', 'good', 'guest', 'staff', 'nice', 'fri...  \n",
       "9      ['goodlife', 'member', 'year', 'personally', '...  \n",
       "10     ['nothing', 'good', 'thing', 'say', 'jason', '...  \n",
       "11     ['far', 'probably', 'worked', 'sweat', 'drippi...  \n",
       "12     ['weekend', 'spot', 'full', 'service', 'comple...  \n",
       "13     ['goodlife', 'member', 'year', 'year', 'switch...  \n",
       "14     ['although', 'not', 'consider', 'uber', 'fit',...  \n",
       "15     ['usual', 'spot', 'lift', 'since', 'live', 'cl...  \n",
       "16     ['love', 'son', 'love', 'ninja', 'zone', 'staf...  \n",
       "17     ['always', 'friendly', 'always', 'clean', 'par...  \n",
       "18     ['worst', 'fucking', 'planet', 'waited', 'minu...  \n",
       "19     ['meaning', 'write', 'review', 'quite', 'somet...  \n",
       "20     ['family', 'used', 'er', 'four', 'past', 'year...  \n",
       "21     ['run', 'really', 'feel', 'like', 'owner', 'no...  \n",
       "22     ['incredibly', 'frustrated', 'apparently', 'co...  \n",
       "23     ['trying', 'cancel', 'membership', 'month', 'c...  \n",
       "24     ['like', 'gold', 'stephanie', 'cool', 'cardio'...  \n",
       "25     ['start', 'pro', 'location', 'not', 'drive', '...  \n",
       "26     ['really', 'like', 'need', 'rule', 'pertaining...  \n",
       "27     ['not', 'typical', 'spin', 'studio', 'difficul...  \n",
       "28     ['people', 'working', 'awesome', 'nice', 'help...  \n",
       "29     ['member', 'month', 'roughly', 'month', 'value...  \n",
       "...                                                  ...  \n",
       "35003  ['thing', 'someone', 'got', 'memo', 'today', '...  \n",
       "35004  ['stop', 'pro', 'result', 'training', 'desk', ...  \n",
       "35005  ['wife', 'considered', 'joining', 'amenity', '...  \n",
       "35006  ['often', 'vacation', 'visited', 'spa', 'hair'...  \n",
       "35007  ['nice', 'affordable', 'considering', 'size', ...  \n",
       "35008  ['offer', 'variety', 'including', 'preschool',...  \n",
       "35009  ['wife', 'cancelled', 'smart', 'membership', '...  \n",
       "35010  ['avoid', 'like', 'plague', 'sold', 'membershi...  \n",
       "35011  ['really', 'like', 'except', 'kid', 'club', 'k...  \n",
       "35012  ['gorgeous', 'spa', 'great', 'cafe', 'wonderfu...  \n",
       "35013  ['everyone', 'need', 'check', 'ryan', 'true', ...  \n",
       "35014  ['ah', 'many', 'good', 'thing', 'say', 'seeing...  \n",
       "35015  ['paid', 'way', 'super', 'sport', 'club', 'mem...  \n",
       "35016  ['scam', 'went', 'tour', 'told', 'requires', '...  \n",
       "35017  ['anthony', 'garcia', 'employee', 'location', ...  \n",
       "35018  ['went', 'early', 'birthday', 'present', 'bff'...  \n",
       "35019  ['poor', 'customer', 'service', 'make', 'pass'...  \n",
       "35020  ['full', 'disclosure', 'climber', 'happen', 'l...  \n",
       "35021  ['looking', 'look', 'anywhere', 'else', 'horri...  \n",
       "35022  ['member', 'year', 'love', 'great', 'coach', '...  \n",
       "35023  ['know', 'lifetime', 'rate', 'member', 'traine...  \n",
       "35024  ['relatively', 'small', 'compared', 'big', 'bo...  \n",
       "35025  ['pretty', 'good', 'working', 'ben', 'always',...  \n",
       "35026  ['love', 'great', 'exchange', 'many', 'employe...  \n",
       "35027  ['satisfied', 'staff', 'service', 'gold', 'can...  \n",
       "35028  ['trick', 'not', 'call', 'elite', 'reason', 'e...  \n",
       "35029  ['lovely', 'little', 'boutique', 'clean', 'goo...  \n",
       "35030  ['former', 'hour', 'facility', 'recently', 'ta...  \n",
       "35031  ['dirty', 'not', 'safe', 'always', 'sanitizer'...  \n",
       "35032  ['husband', 'joined', 'specifically', 'locatio...  \n",
       "\n",
       "[35033 rows x 5 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_clean = pd.read_csv(\"review_train_aftercleaning.csv\")\n",
    "data_train_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time: 810.5755780000001 Seconds\n"
     ]
    }
   ],
   "source": [
    "## train words embedding model\n",
    "## define dimension of need\n",
    "size = 300\n",
    "start = time.process_time()\n",
    "w2v = Word2Vec(review_train_clean, size=size, window=10, min_count=1,\n",
    "            workers=multiprocessing.cpu_count(), sg=1, iter=10, negative=20)\n",
    "end = time.process_time()\n",
    "print('Running time: %s Seconds'%(end-start))\n",
    "## save model as w2vmodel\n",
    "w2v.save('w2vmodel')\n",
    "## load model\n",
    "model = Word2Vec.load('w2vmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:01<00:00, 2687.83it/s]\n"
     ]
    }
   ],
   "source": [
    "## for each review, get 1*size matrix use average of words matrix \n",
    "trysize=5000\n",
    "predictors = np.empty((trysize,size), float)\n",
    "for i in tqdm(range(trysize)):\n",
    "    predictors[i,] = pd.DataFrame(model.wv[review_train_clean[i]]).mean()\n",
    "    \n",
    "response = pd.DataFrame(data_train)['stars']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [11:18<00:00,  9.35it/s]\n"
     ]
    }
   ],
   "source": [
    "size = 300\n",
    "trysize=5000\n",
    "predictors_weighted = np.empty((trysize,size), float)\n",
    "for i in tqdm(range(trysize)):\n",
    "    tfidf_dict = tfidf_4_web(review_train_clean[i],data_train)\n",
    "    tfidf_mul = []\n",
    "    for word in review_train_clean[i]:\n",
    "        tfidf_mul.append(tfidf_dict[word])\n",
    "    predictors_weighted[i,] = (pd.DataFrame(model.wv[review_train_clean[i]]).mul(tfidf_mul,axis=0)).mean()\n",
    "    \n",
    "response = pd.DataFrame(data_train)['stars']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE =  1.331465358167459\n"
     ]
    }
   ],
   "source": [
    "## logistic regression\n",
    "model_logit = LogisticRegression(solver = 'lbfgs', multi_class='multinomial',max_iter=500)\n",
    "model_logit.fit(predictors_weighted, response)\n",
    "## rmse for regression\n",
    "y_fitted = model_logit.predict(predictors_weighted)\n",
    "print(\"RMSE = \", sqrt(sum(np.square(response-y_fitted)) / len(y_fitted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
